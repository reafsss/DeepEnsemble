{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1623683164616,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "dVpBmTS2QxV6",
    "outputId": "b494989e-ae32-41ca-deaf-3a35efecfb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uncertainty_baselines\n",
      "  Cloning https://github.com/google/uncertainty-baselines.git to c:\\windows\\temp\\pip-install-3kdpk2yq\\uncertainty-baselines_2f8f61002d9543c291cc253366fc0549\n",
      "Requirement already satisfied: absl-py>=0.8.1 in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (0.12.0)\n",
      "Requirement already satisfied: astunparse in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (1.6.3)\n",
      "Requirement already satisfied: chardet in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (4.0.0)\n",
      "Requirement already satisfied: flatbuffers in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (1.12)\n",
      "Requirement already satisfied: idna in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (2.10)\n",
      "Requirement already satisfied: ml_collections in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (0.1.0)\n",
      "Requirement already satisfied: numpy>=1.7 in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (1.19.5)\n",
      "Requirement already satisfied: opt_einsum in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (3.3.0)\n",
      "Requirement already satisfied: tb-nightly in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (2.6.0a20210605)\n",
      "Requirement already satisfied: tensorflow-datasets in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (4.3.0)\n",
      "Requirement already satisfied: tf-nightly in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (2.6.0.dev20210604)\n",
      "Requirement already satisfied: tfa-nightly in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (0.14.0.dev20210605230927)\n",
      "Requirement already satisfied: urllib3 in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (1.26.4)\n",
      "Requirement already satisfied: zipp in d:\\ana\\lib\\site-packages (from uncertainty_baselines) (3.4.1)\n",
      "Requirement already satisfied: six in d:\\ana\\lib\\site-packages (from absl-py>=0.8.1->uncertainty_baselines) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\ana\\lib\\site-packages (from astunparse->uncertainty_baselines) (0.36.2)\n",
      "Requirement already satisfied: PyYAML in d:\\ana\\lib\\site-packages (from ml_collections->uncertainty_baselines) (5.4.1)\n",
      "Requirement already satisfied: contextlib2 in d:\\ana\\lib\\site-packages (from ml_collections->uncertainty_baselines) (0.6.0.post1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (1.30.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (1.38.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (3.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ana\\lib\\site-packages (from tb-nightly->uncertainty_baselines) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly->uncertainty_baselines) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly->uncertainty_baselines) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly->uncertainty_baselines) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ana\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->uncertainty_baselines) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\ana\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly->uncertainty_baselines) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ana\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly->uncertainty_baselines) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ana\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->uncertainty_baselines) (3.1.1)\n",
      "Requirement already satisfied: future in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (0.18.2)\n",
      "Requirement already satisfied: tensorflow-metadata in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (1.0.0)\n",
      "Requirement already satisfied: tqdm in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (4.59.0)\n",
      "Requirement already satisfied: promise in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (2.3)\n",
      "Requirement already satisfied: termcolor in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (1.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (20.3.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (5.1.4)\n",
      "Requirement already satisfied: dill in d:\\ana\\lib\\site-packages (from tensorflow-datasets->uncertainty_baselines) (0.3.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in d:\\ana\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets->uncertainty_baselines) (1.53.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (0.2.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (1.1.2)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (2.5.0.dev2021032601)\n",
      "Requirement already satisfied: gast==0.4.0 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (3.7.4.3)\n",
      "Requirement already satisfied: keras-nightly~=2.6.0.dev in d:\\ana\\lib\\site-packages (from tf-nightly->uncertainty_baselines) (2.6.0.dev2021060500)\n",
      "Requirement already satisfied: typeguard>=2.7 in d:\\ana\\lib\\site-packages (from tfa-nightly->uncertainty_baselines) (2.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/google/uncertainty-baselines.git 'C:\\Windows\\Temp\\pip-install-3kdpk2yq\\uncertainty-baselines_2f8f61002d9543c291cc253366fc0549'\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/google/uncertainty-baselines.git#egg=uncertainty_baselines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2412,
     "status": "ok",
     "timestamp": 1623683167024,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "SrsFLW26bXJY",
    "outputId": "f51b5e1d-2b54-43e9-8373-5e3d3c85d8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting robustness_metrics\n",
      "  Cloning https://github.com/google-research/robustness_metrics.git to c:\\windows\\temp\\pip-install-ibydhv_q\\robustness-metrics_a650e18e1010432b9b046de37e9bd6f2\n",
      "Requirement already satisfied: absl-py in d:\\ana\\lib\\site-packages (from robustness_metrics) (0.12.0)\n",
      "Requirement already satisfied: pandas in d:\\ana\\lib\\site-packages (from robustness_metrics) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\ana\\lib\\site-packages (from robustness_metrics) (0.24.1)\n",
      "Requirement already satisfied: tabulate in d:\\ana\\lib\\site-packages (from robustness_metrics) (0.8.9)\n",
      "Requirement already satisfied: tensorflow_datasets in d:\\ana\\lib\\site-packages (from robustness_metrics) (4.3.0)\n",
      "Requirement already satisfied: tensorflow_hub in d:\\ana\\lib\\site-packages (from robustness_metrics) (0.12.0)\n",
      "Requirement already satisfied: tf-nightly in d:\\ana\\lib\\site-packages (from robustness_metrics) (2.6.0.dev20210604)\n",
      "Requirement already satisfied: tfp-nightly in d:\\ana\\lib\\site-packages (from robustness_metrics) (0.14.0.dev20210605)\n",
      "Requirement already satisfied: six in d:\\ana\\lib\\site-packages (from absl-py->robustness_metrics) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\ana\\lib\\site-packages (from pandas->robustness_metrics) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\ana\\lib\\site-packages (from pandas->robustness_metrics) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in d:\\ana\\lib\\site-packages (from pandas->robustness_metrics) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\ana\\lib\\site-packages (from scikit-learn->robustness_metrics) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\ana\\lib\\site-packages (from scikit-learn->robustness_metrics) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\ana\\lib\\site-packages (from scikit-learn->robustness_metrics) (1.0.1)\n",
      "Requirement already satisfied: future in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (0.18.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (20.3.0)\n",
      "Requirement already satisfied: tensorflow-metadata in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (1.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: termcolor in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (1.1.0)\n",
      "Requirement already satisfied: dill in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (0.3.3)\n",
      "Requirement already satisfied: importlib-resources in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (5.1.4)\n",
      "Requirement already satisfied: promise in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (2.3)\n",
      "Requirement already satisfied: tqdm in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (4.59.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (3.17.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\ana\\lib\\site-packages (from tensorflow_datasets->robustness_metrics) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets->robustness_metrics) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets->robustness_metrics) (4.0.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/google-research/robustness_metrics.git 'C:\\Windows\\Temp\\pip-install-ibydhv_q\\robustness-metrics_a650e18e1010432b9b046de37e9bd6f2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets->robustness_metrics) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets->robustness_metrics) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\ana\\lib\\site-packages (from importlib-resources->tensorflow_datasets->robustness_metrics) (3.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in d:\\ana\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets->robustness_metrics) (1.53.0)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (2.5.0.dev2021032601)\n",
      "Requirement already satisfied: tb-nightly~=2.6.0.a in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (2.6.0a20210605)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (1.1.2)\n",
      "Requirement already satisfied: keras-nightly~=2.6.0.dev in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (2.6.0.dev2021060500)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (0.36.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (1.12)\n",
      "Requirement already satisfied: gast==0.4.0 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (1.38.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in d:\\ana\\lib\\site-packages (from tf-nightly->robustness_metrics) (3.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\ana\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (1.30.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\ana\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ana\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\ana\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ana\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly->robustness_metrics) (3.1.1)\n",
      "Requirement already satisfied: dm-tree in d:\\ana\\lib\\site-packages (from tfp-nightly->robustness_metrics) (0.1.6)\n",
      "Requirement already satisfied: decorator in d:\\ana\\lib\\site-packages (from tfp-nightly->robustness_metrics) (5.0.6)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in d:\\ana\\lib\\site-packages (from tfp-nightly->robustness_metrics) (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "pip install \"git+https://github.com/google-research/robustness_metrics.git#egg=robustness_metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5390,
     "status": "ok",
     "timestamp": 1623683172409,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "9tUhcLEebZny",
    "outputId": "8857420e-5459-4da2-e35a-62b79b0f2180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/google/edward2\n",
      "  Cloning https://github.com/google/edward2 to c:\\windows\\temp\\pip-req-build-0mb6z4_x\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/google/edward2 'C:\\Windows\\Temp\\pip-req-build-0mb6z4_x'\n"
     ]
    }
   ],
   "source": [
    "pip install \"git+https://github.com/google/edward2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4622,
     "status": "ok",
     "timestamp": 1623683177019,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "j5cgRbllGqK0",
    "outputId": "d7e21cc6-633f-48f5-c62b-3c1eb32f9c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in d:\\ana\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in d:\\ana\\lib\\site-packages (from tensorflow_addons) (2.12.1)\n",
      "Requirement already satisfied: tensorflow_datasets in d:\\ana\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: six in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: numpy in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (3.17.2)\n",
      "Requirement already satisfied: tqdm in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (4.59.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: dill in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (0.3.3)\n",
      "Requirement already satisfied: importlib-resources in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (5.1.4)\n",
      "Requirement already satisfied: termcolor in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: promise in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: future in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: absl-py in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (0.12.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied: tensorflow-metadata in d:\\ana\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\ana\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\ana\\lib\\site-packages (from importlib-resources->tensorflow_datasets) (3.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in d:\\ana\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n",
    "!pip install tensorflow_datasets --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY10M9WKNwBB"
   },
   "source": [
    "#시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19148,
     "status": "ok",
     "timestamp": 1623683196162,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "3CoeNznmInaA",
    "outputId": "0a9ef8ab-f772-4440-d4b9-acf4d4955a6b"
   },
   "outputs": [],
   "source": [
    "# # 구글 드라이브 마운트\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1623683196163,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "dhzxWl_2Ip1D"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('/content/gdrive/My Drive/tmp/cifar')\n",
    "# print(len(df))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 11139,
     "status": "ok",
     "timestamp": 1623683207291,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "P-W9SXgTOA1u",
    "outputId": "6440633c-7829-407b-c175-636601d1b3df"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# src = list(files.upload().values())[0]\n",
    "# open('utils.py','wb').write(src)\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Time': list(range(0,15))\n",
    "                      })\n",
    "df.to_csv('D:\\\\test3\\\\tttt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Utilities for CIFAR-10 and CIFAR-100.\"\"\"\n",
    "\n",
    "import os\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# common flags\n",
    "flags.DEFINE_string(\"f\", \"\", \"kernel\")\n",
    "flags.DEFINE_float('base_learning_rate', 0.1,\n",
    "                   'Base learning rate when total batch size is 128. It is '\n",
    "                   'scaled by the ratio of the total batch size to 128.')\n",
    "flags.DEFINE_integer('checkpoint_interval', 25,\n",
    "                     'Number of epochs between saving checkpoints. Use -1 to '\n",
    "                     'never save checkpoints.')\n",
    "# TODO(ghassen): consider adding CIFAR-100-C to TFDS.\n",
    "flags.DEFINE_string('cifar100_c_path', None,\n",
    "                    'Path to the TFRecords files for CIFAR-100-C. Only valid '\n",
    "                    '(and required) if dataset is cifar100 and corruptions.')\n",
    "flags.DEFINE_integer('corruptions_interval', -1,\n",
    "                     'Number of epochs between evaluating on the corrupted '\n",
    "                     'test data. Use -1 to never evaluate.')\n",
    "flags.DEFINE_enum('dataset', 'cifar10',\n",
    "                  enum_values=['cifar10', 'cifar100'],\n",
    "                  help='Dataset.')\n",
    "flags.DEFINE_string('data_dir', None,\n",
    "                    'data_dir to be used for tfds dataset construction.'\n",
    "                    'It is required when training with cloud TPUs')\n",
    "flags.DEFINE_bool('download_data', False,\n",
    "                  'Whether to download data locally when initializing a '\n",
    "                  'dataset.')\n",
    "flags.DEFINE_float('l2', 2e-4, 'L2 regularization coefficient.')\n",
    "flags.DEFINE_float('lr_decay_ratio', 0.2, 'Amount to decay learning rate.')\n",
    "flags.DEFINE_list('lr_decay_epochs', ['60', '120', '160'],\n",
    "                  'Epochs to decay learning rate by.')\n",
    "flags.DEFINE_integer('lr_warmup_epochs', 1,\n",
    "                     'Number of epochs for a linear warmup to the initial '\n",
    "                     'learning rate. Use 0 to do no warmup.')\n",
    "flags.DEFINE_integer('num_bins', 15, 'Number of bins for ECE.')\n",
    "flags.DEFINE_float('one_minus_momentum', 0.1, 'Optimizer momentum.')\n",
    "flags.DEFINE_string('output_dir', 'D:\\\\test3', 'Output directory.')\n",
    "flags.DEFINE_integer('per_core_batch_size', 64,\n",
    "                     'Batch size per TPU core/GPU. The number of new '\n",
    "                     'datapoints gathered per batch is this number divided by '\n",
    "                     'ensemble_size (we tile the batch by that # of times).')\n",
    "flags.DEFINE_integer('seed', 42, 'Random seed.')\n",
    "flags.DEFINE_integer('train_epochs', 200, 'Number of training epochs.')\n",
    "flags.DEFINE_float('train_proportion', default=1.0,\n",
    "                   help='only use a proportion of training set.')\n",
    "flags.register_validator('train_proportion',\n",
    "                         lambda tp: tp > 0.0 and tp <= 1.0,\n",
    "                         message='--train_proportion must be in (0, 1].')\n",
    "\n",
    "# Accelerator flags.\n",
    "flags.DEFINE_bool('use_gpu', False, 'Whether to run on GPU or otherwise TPU.')\n",
    "flags.DEFINE_integer('num_cores', 8, 'Number of TPU cores or number of GPUs.')\n",
    "flags.DEFINE_string('tpu', None,\n",
    "                    'Name of the TPU. Only used if use_gpu is False.')\n",
    "flags.DEFINE_bool('use_bfloat16', False, 'Whether to use mixed precision.')\n",
    "\n",
    "\n",
    "def load_cifar100_c(corruption_name,\n",
    "                    corruption_intensity,\n",
    "                    batch_size,\n",
    "                    use_bfloat16,\n",
    "                    path,\n",
    "                    drop_remainder=True,\n",
    "                    normalize=True,\n",
    "                    standarize=True):\n",
    "  \"\"\"Loads CIFAR-100-C dataset.\"\"\"\n",
    "  if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  filename = path + '{0}-{1}.tfrecords'.format(corruption_name,\n",
    "                                               corruption_intensity)\n",
    "  def preprocess(serialized_example):\n",
    "    \"\"\"Preprocess a serialized example for CIFAR100-C.\"\"\"\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.cast(tf.reshape(image, [32, 32, 3]), dtype)\n",
    "    image = tf.image.convert_image_dtype(image, dtype)\n",
    "    image = image / 255  # to convert into the [0, 1) range\n",
    "    if normalize:\n",
    "      mean = tf.constant([0.4914, 0.4822, 0.4465], dtype=dtype)\n",
    "      std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype)\n",
    "      image = (image - mean) / std\n",
    "    elif standarize:\n",
    "      # Normalize per-image using mean/stddev computed across pixels.\n",
    "      image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(features['label'], dtype)\n",
    "    return image, label\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset(filename, buffer_size=16 * 1000 * 1000)\n",
    "  dataset = dataset.map(\n",
    "      preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def load_cifar10_c(corruption_name,\n",
    "                   corruption_intensity,\n",
    "                   batch_size,\n",
    "                   use_bfloat16,\n",
    "                   drop_remainder=True,\n",
    "                   normalize=True):\n",
    "  \"\"\"Loads CIFAR-10-C dataset.\"\"\"\n",
    "  if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  corruption = corruption_name + '_' + str(corruption_intensity)\n",
    "  def preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype)\n",
    "    if normalize:\n",
    "      # We use the convention of mean = np.mean(train_images, axis=(0,1,2))\n",
    "      # and std = np.std(train_images, axis=(0,1,2)).\n",
    "      mean = tf.constant([0.4914, 0.4822, 0.4465], dtype=dtype)\n",
    "      std = tf.constant([0.2470, 0.2435, 0.2616], dtype=dtype)\n",
    "      # Previously, std = np.mean(np.std(train_images, axis=(1, 2)), axis=0)\n",
    "      # which gave std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype).\n",
    "      # However, we change convention to use the std over the entire training\n",
    "      # set instead.\n",
    "      image = (image - mean) / std\n",
    "    label = tf.cast(label, dtype)\n",
    "    return image, label\n",
    "\n",
    "  dataset = tfds.load(name='cifar10_corrupted/{}'.format(corruption),\n",
    "                      split=tfds.Split.TEST,\n",
    "                      as_supervised=True)\n",
    "  dataset = dataset.map(\n",
    "      preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# TODO(ghassen,trandustin): Push this metadata upstream to TFDS.\n",
    "def load_corrupted_test_info(dataset):\n",
    "  \"\"\"Loads information for CIFAR-10-C.\"\"\"\n",
    "  if dataset == 'cifar10':\n",
    "    corruption_types = [\n",
    "        'gaussian_noise',\n",
    "        'shot_noise',\n",
    "        'impulse_noise',\n",
    "        'defocus_blur',\n",
    "        'frosted_glass_blur',\n",
    "        'motion_blur',\n",
    "        'zoom_blur',\n",
    "        'snow',\n",
    "        'frost',\n",
    "        'fog',\n",
    "        'brightness',\n",
    "        'contrast',\n",
    "        'elastic',\n",
    "        'pixelate',\n",
    "        'jpeg_compression',\n",
    "    ]\n",
    "  else:\n",
    "    corruption_types = [\n",
    "        'brightness',\n",
    "        'contrast',\n",
    "        'defocus_blur',\n",
    "        'elastic_transform',\n",
    "        'fog',\n",
    "        'frost',\n",
    "        'glass_blur',  # Called frosted_glass_blur in CIFAR-10.\n",
    "        'gaussian_blur',\n",
    "        'gaussian_noise',\n",
    "        'impulse_noise',\n",
    "        'jpeg_compression',\n",
    "        'pixelate',\n",
    "        'saturate',\n",
    "        'shot_noise',\n",
    "        'spatter',\n",
    "        'speckle_noise',  # Does not exist for CIFAR-10.\n",
    "        'zoom_blur',\n",
    "    ]\n",
    "  max_intensity = 5\n",
    "  return corruption_types, max_intensity\n",
    "\n",
    "\n",
    "# TODO(baselines): Remove reliance on hard-coded metric names.\n",
    "def aggregate_corrupt_metrics(metrics,\n",
    "                              corruption_types,\n",
    "                              max_intensity=5,\n",
    "                              log_fine_metrics=False,\n",
    "                              corrupt_diversity=None,\n",
    "                              output_dir=None,\n",
    "                              prefix='test'):\n",
    "  \"\"\"Aggregates metrics across intensities and corruption types.\n",
    "  Args:\n",
    "    metrics: Dictionary of tf.keras.metrics to be aggregated.\n",
    "    corruption_types: List of corruption types.\n",
    "    max_intensity: Int, of maximum intensity.\n",
    "    log_fine_metrics: Bool, whether log fine metrics to main training script.\n",
    "    corrupt_diversity: Dictionary of diversity metrics on corrupted datasets.\n",
    "    output_dir: Str, the path to save the aggregated results.\n",
    "    prefix: Str, the prefix before metrics such as 'test', 'lineareval'.\n",
    "  Returns:\n",
    "    Dictionary of aggregated results.\n",
    "  \"\"\"\n",
    "  diversity_keys = ['disagreement', 'cosine_similarity', 'average_kl']\n",
    "  results = {\n",
    "      '{}/nll_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/kl_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/elbo_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/accuracy_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/ece_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/member_acc_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/member_ece_mean_corrupted'.format(prefix): 0.\n",
    "  }\n",
    "  fine_metrics_results = {}\n",
    "  if corrupt_diversity is not None:\n",
    "    for key in diversity_keys:\n",
    "      results['corrupt_diversity/{}_mean_corrupted'.format(key)] = 0.\n",
    "\n",
    "  for intensity in range(1, max_intensity + 1):\n",
    "    nll = np.zeros(len(corruption_types))\n",
    "    kl = np.zeros(len(corruption_types))\n",
    "    elbo = np.zeros(len(corruption_types))\n",
    "    acc = np.zeros(len(corruption_types))\n",
    "    ece = np.zeros(len(corruption_types))\n",
    "    member_acc = np.zeros(len(corruption_types))\n",
    "    member_ece = np.zeros(len(corruption_types))\n",
    "    disagreement = np.zeros(len(corruption_types))\n",
    "    cosine_similarity = np.zeros(len(corruption_types))\n",
    "    average_kl = np.zeros(len(corruption_types))\n",
    "\n",
    "    for i in range(len(corruption_types)):\n",
    "      dataset_name = '{0}_{1}'.format(corruption_types[i], intensity)\n",
    "      nll[i] = metrics['{0}/nll_{1}'.format(prefix, dataset_name)].result()\n",
    "      if '{0}/kl_{1}'.format(prefix, dataset_name) in metrics.keys():\n",
    "        kl[i] = metrics['{0}/kl_{1}'.format(prefix, dataset_name)].result()\n",
    "      else:\n",
    "        kl[i] = 0.\n",
    "      if '{0}/elbo_{1}'.format(prefix, dataset_name) in metrics.keys():\n",
    "        elbo[i] = metrics['{0}/elbo_{1}'.format(prefix, dataset_name)].result()\n",
    "      else:\n",
    "        elbo[i] = 0.\n",
    "      acc[i] = metrics['{0}/accuracy_{1}'.format(prefix, dataset_name)].result()\n",
    "      ece[i] = metrics['{0}/ece_{1}'.format(prefix, dataset_name)].result()\n",
    "      if '{0}/member_acc_mean_{1}'.format(prefix,\n",
    "                                          dataset_name) in metrics.keys():\n",
    "        member_acc[i] = metrics['{0}/member_acc_mean_{1}'.format(\n",
    "            prefix, dataset_name)].result()\n",
    "      else:\n",
    "        member_acc[i] = 0.\n",
    "      if '{0}/member_ece_mean_{1}'.format(prefix,\n",
    "                                          dataset_name) in metrics.keys():\n",
    "        member_ece[i] = metrics['{0}/member_ece_mean_{1}'.format(\n",
    "            prefix, dataset_name)].result()\n",
    "        member_ece[i] = 0.\n",
    "      if corrupt_diversity is not None:\n",
    "        disagreement[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/disagreement_{}'.format(\n",
    "                dataset_name)].result())\n",
    "        # Normalize the corrupt disagreement by its error rate.\n",
    "        error = 1 - acc[i] + tf.keras.backend.epsilon()\n",
    "        cosine_similarity[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/cosine_similarity_{}'.format(\n",
    "                dataset_name)].result()) / error\n",
    "        average_kl[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/average_kl_{}'.format(\n",
    "                dataset_name)].result())\n",
    "      if log_fine_metrics or output_dir is not None:\n",
    "        fine_metrics_results['{0}/nll_{1}'.format(prefix,\n",
    "                                                  dataset_name)] = nll[i]\n",
    "        fine_metrics_results['{0}/kl_{1}'.format(prefix,\n",
    "                                                 dataset_name)] = kl[i]\n",
    "        fine_metrics_results['{0}/elbo_{1}'.format(prefix,\n",
    "                                                   dataset_name)] = elbo[i]\n",
    "        fine_metrics_results['{0}/accuracy_{1}'.format(prefix,\n",
    "                                                       dataset_name)] = acc[i]\n",
    "        fine_metrics_results['{0}/ece_{1}'.format(prefix,\n",
    "                                                  dataset_name)] = ece[i]\n",
    "        if corrupt_diversity is not None:\n",
    "          fine_metrics_results['corrupt_diversity/disagreement_{}'.format(\n",
    "              dataset_name)] = disagreement[i]\n",
    "          fine_metrics_results['corrupt_diversity/cosine_similarity_{}'.format(\n",
    "              dataset_name)] = cosine_similarity[i]\n",
    "          fine_metrics_results['corrupt_diversity/average_kl_{}'.format(\n",
    "              dataset_name)] = average_kl[i]\n",
    "    avg_nll = np.mean(nll)\n",
    "    avg_kl = np.mean(kl)\n",
    "    avg_elbo = np.mean(elbo)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "    avg_ece = np.mean(ece)\n",
    "    avg_member_acc = np.mean(member_acc)\n",
    "    avg_member_ece = np.mean(member_ece)\n",
    "    results['{0}/nll_mean_{1}'.format(prefix, intensity)] = avg_nll\n",
    "    results['{0}/kl_mean_{1}'.format(prefix, intensity)] = avg_kl\n",
    "    results['{0}/elbo_mean_{1}'.format(prefix, intensity)] = avg_elbo\n",
    "    results['{0}/accuracy_mean_{1}'.format(prefix, intensity)] = avg_accuracy\n",
    "    results['{0}/ece_mean_{1}'.format(prefix, intensity)] = avg_ece\n",
    "    results['{0}/nll_median_{1}'.format(prefix, intensity)] = np.median(nll)\n",
    "    results['{0}/kl_median_{1}'.format(prefix, intensity)] = np.median(kl)\n",
    "    results['{0}/elbo_median_{1}'.format(prefix, intensity)] = np.median(elbo)\n",
    "    results['{0}/accuracy_median_{1}'.format(prefix,\n",
    "                                             intensity)] = np.median(acc)\n",
    "    results['{0}/ece_median_{1}'.format(prefix, intensity)] = np.median(ece)\n",
    "    results['{0}/member_acc_mean_{1}'.format(prefix,\n",
    "                                             intensity)] = avg_member_acc\n",
    "    results['{0}/member_ece_mean_{1}'.format(prefix,\n",
    "                                             intensity)] = avg_member_ece\n",
    "    results['{}/nll_mean_corrupted'.format(prefix)] += avg_nll\n",
    "    results['{}/kl_mean_corrupted'.format(prefix)] += avg_kl\n",
    "    results['{}/elbo_mean_corrupted'.format(prefix)] += avg_elbo\n",
    "    results['{}/accuracy_mean_corrupted'.format(prefix)] += avg_accuracy\n",
    "    results['{}/ece_mean_corrupted'.format(prefix)] += avg_ece\n",
    "    results['{}/member_acc_mean_corrupted'.format(prefix)] += avg_member_acc\n",
    "    results['{}/member_ece_mean_corrupted'.format(prefix)] += avg_member_ece\n",
    "    if corrupt_diversity is not None:\n",
    "      avg_diversity_metrics = [np.mean(disagreement), np.mean(\n",
    "          cosine_similarity), np.mean(average_kl)]\n",
    "      for key, avg in zip(diversity_keys, avg_diversity_metrics):\n",
    "        results['corrupt_diversity/{}_mean_{}'.format(\n",
    "            key, intensity)] = avg\n",
    "        results['corrupt_diversity/{}_mean_corrupted'.format(key)] += avg\n",
    "\n",
    "  results['{}/nll_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/kl_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/elbo_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/accuracy_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/ece_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/member_acc_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/member_ece_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  if corrupt_diversity is not None:\n",
    "    for key in diversity_keys:\n",
    "      results['corrupt_diversity/{}_mean_corrupted'.format(\n",
    "          key)] /= max_intensity\n",
    "\n",
    "  fine_metrics_results.update(results)\n",
    "  if output_dir is not None:\n",
    "    save_file_name = os.path.join(output_dir, 'corrupt_metrics.npz')\n",
    "    with tf.io.gfile.GFile(save_file_name, 'w') as f:\n",
    "      np.save(f, fine_metrics_results)\n",
    "\n",
    "  if log_fine_metrics:\n",
    "    return fine_metrics_results\n",
    "  else:\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oRio5jMcvJW"
   },
   "source": [
    "# cifar 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9755,
     "status": "ok",
     "timestamp": 1623683217042,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "a6lISZ6rZ43e",
    "outputId": "37a5fd65-48aa-4cb6-db40-59fec2b67e3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\lib\\site-packages\\uncertainty_baselines\\datasets\\datasets.py:51: UserWarning: Skipped due to ImportError: No module named 'librosa'\n",
      "  warnings.warn(f'Skipped due to ImportError: {e}')\n",
      "D:\\ana\\lib\\site-packages\\uncertainty_baselines\\datasets\\__init__.py:59: UserWarning: Skipped due to ImportError: No module named 'librosa'\n",
      "  warnings.warn(f'Skipped due to ImportError: {e}')\n",
      "D:\\ana\\lib\\site-packages\\uncertainty_baselines\\models\\models.py:39: UserWarning: Skipped due to ImportError: No module named 'official'\n",
      "  warnings.warn(f'Skipped due to ImportError: {e}')\n",
      "D:\\ana\\lib\\site-packages\\uncertainty_baselines\\models\\__init__.py:69: UserWarning: Skipped due to ImportError: No module named 'official'\n",
      "  warnings.warn(f'Skipped due to ImportError: {e}')\n",
      "WARNING:absl:No module named 'torch'\n",
      "D:\\ana\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.6.0-dev20210604). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cifar데이터셋\n",
    "\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"CIFAR{10,100} dataset builders.\"\"\"\n",
    "\n",
    "from typing import Any, Dict, Optional, Union\n",
    "\n",
    "from robustness_metrics.common import types\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from uncertainty_baselines.datasets import augment_utils\n",
    "from uncertainty_baselines.datasets import augmix\n",
    "from uncertainty_baselines.datasets import base\n",
    "\n",
    "# We use the convention of using mean = np.mean(train_images, axis=(0,1,2))\n",
    "# and std = np.std(train_images, axis=(0,1,2)).\n",
    "CIFAR10_MEAN = tf.constant([0.4914, 0.4822, 0.4465])\n",
    "CIFAR10_STD = tf.constant([0.2470, 0.2435, 0.2616])\n",
    "# Previously we used std = np.mean(np.std(train_images, axis=(1, 2)), axis=0)\n",
    "# which gave std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype), however\n",
    "# we change convention to use the std over the entire training set instead.\n",
    "\n",
    "\n",
    "def _tuple_dict_fn_converter(fn, *args):\n",
    "\n",
    "  def dict_fn(batch_dict):\n",
    "    images, labels = fn(*args, batch_dict['features'], batch_dict['labels'])\n",
    "    return {'features': images, 'labels': labels}\n",
    "\n",
    "  return dict_fn\n",
    "\n",
    "\n",
    "class _CifarDataset(base.BaseDataset):\n",
    "  \"\"\"CIFAR dataset builder abstract class.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      name: str,\n",
    "      fingerprint_key: str,\n",
    "      split: str,\n",
    "      seed: Optional[Union[int, tf.Tensor]] = None,\n",
    "      validation_percent: float = 0.0,\n",
    "      shuffle_buffer_size: Optional[int] = None,\n",
    "      num_parallel_parser_calls: int = 64,\n",
    "      drop_remainder: bool = True,\n",
    "      normalize: bool = True,\n",
    "      try_gcs: bool = False,\n",
    "      download_data: bool = False,\n",
    "      use_bfloat16: bool = False,\n",
    "      aug_params: Optional[Dict[str, Any]] = None,\n",
    "      data_dir: Optional[str] = None,\n",
    "      is_training: Optional[bool] = None,\n",
    "      **unused_kwargs: Dict[str, Any]):\n",
    "    \"\"\"Create a CIFAR10 or CIFAR100 tf.data.Dataset builder.\n",
    "    Args:\n",
    "      name: the name of this dataset, either 'cifar10' or 'cifar100'.\n",
    "      fingerprint_key: The name of the feature holding a string that will be\n",
    "        used to create an element id using a fingerprinting function. If None,\n",
    "        then `ds.enumerate()` is added before the `ds.map(preprocessing_fn)` is\n",
    "        called and an `id` field is added to the example Dict.\n",
    "      split: a dataset split, either a custom tfds.Split or one of the\n",
    "        tfds.Split enums [TRAIN, VALIDAITON, TEST] or their lowercase string\n",
    "        names.\n",
    "      seed: the seed used as a source of randomness.\n",
    "      validation_percent: the percent of the training set to use as a validation\n",
    "        set.\n",
    "      shuffle_buffer_size: the number of example to use in the shuffle buffer\n",
    "        for tf.data.Dataset.shuffle().\n",
    "      num_parallel_parser_calls: the number of parallel threads to use while\n",
    "        preprocessing in tf.data.Dataset.map().\n",
    "      drop_remainder: whether or not to drop the last batch of data if the\n",
    "        number of points is not exactly equal to the batch size. This option\n",
    "        needs to be True for running on TPUs.\n",
    "      normalize: whether or not to normalize each image by the CIFAR dataset\n",
    "        mean and stddev.\n",
    "      try_gcs: Whether or not to try to use the GCS stored versions of dataset\n",
    "        files.\n",
    "      download_data: Whether or not to download data before loading.\n",
    "      use_bfloat16: Whether or not to load the data in bfloat16 or float32.\n",
    "      aug_params: hyperparameters for the data augmentation pre-processing.\n",
    "      data_dir: Directory to read/write data, that is passed to the\n",
    "        tfds dataset_builder as a data_dir parameter.\n",
    "      is_training: Whether or not the given `split` is the training split. Only\n",
    "        required when the passed split is not one of ['train', 'validation',\n",
    "        'test', tfds.Split.TRAIN, tfds.Split.VALIDATION, tfds.Split.TEST].\n",
    "    \"\"\"\n",
    "    # dataset_builder = tfds.builder('cifar10')\n",
    "    # dataset_builder.download_and_prepare() \n",
    "    \n",
    "    self._normalize = normalize\n",
    "    dataset_builder = tfds.builder(\n",
    "        name, \n",
    "        #try_gcs=try_gcs,\n",
    "        data_dir=data_dir)\n",
    "    #dataset_builder.download_and_prepare()\n",
    "    if is_training is None:\n",
    "      is_training = split in ['train', tfds.Split.TRAIN]\n",
    "    new_split = base.get_validation_percent_split(\n",
    "        dataset_builder, validation_percent, split)\n",
    "    super(_CifarDataset, self).__init__(\n",
    "        name=name,\n",
    "        dataset_builder=dataset_builder,\n",
    "        split=new_split,\n",
    "        seed=seed,\n",
    "        is_training=is_training,\n",
    "        shuffle_buffer_size=shuffle_buffer_size,\n",
    "        num_parallel_parser_calls=num_parallel_parser_calls,\n",
    "        drop_remainder=drop_remainder,\n",
    "        fingerprint_key=fingerprint_key,\n",
    "        download_data=download_data,\n",
    "        cache=True)\n",
    "\n",
    "    self._use_bfloat16 = use_bfloat16\n",
    "    if aug_params is None:\n",
    "      aug_params = {}\n",
    "    self._adaptive_mixup = aug_params.get('adaptive_mixup', False)\n",
    "    ensemble_size = aug_params.get('ensemble_size', 1)\n",
    "    if self._adaptive_mixup and 'mixup_coeff' not in aug_params:\n",
    "      # Hard target in the first epoch!\n",
    "      aug_params['mixup_coeff'] = tf.ones([ensemble_size, 10])\n",
    "    self._aug_params = aug_params\n",
    "\n",
    "  def _create_process_example_fn(self) -> base.PreProcessFn:\n",
    "\n",
    "    def _example_parser(example: types.Features) -> types.Features:\n",
    "      \"\"\"A pre-process function to return images in [0, 1].\"\"\"\n",
    "      image = example['image']\n",
    "      image_dtype = tf.bfloat16 if self._use_bfloat16 else tf.float32\n",
    "      use_augmix = self._aug_params.get('augmix', False)\n",
    "      if self._is_training:\n",
    "        image_shape = tf.shape(image)\n",
    "        # Expand the image by 2 pixels, then crop back down to 32x32.\n",
    "        image = tf.image.resize_with_crop_or_pad(\n",
    "            image, image_shape[0] + 4, image_shape[1] + 4)\n",
    "        # Note that self._seed will already be shape (2,), as is required for\n",
    "        # stateless random ops, and so will per_example_step_seed.\n",
    "        per_example_step_seed = tf.random.experimental.stateless_fold_in(\n",
    "            self._seed, example[self._enumerate_id_key])\n",
    "        # per_example_step_seeds will be of size (num, 3).\n",
    "        # First for random_crop, second for flip, third optionally for\n",
    "        # RandAugment, and foruth optionally for Augmix.\n",
    "        per_example_step_seeds = tf.random.experimental.stateless_split(\n",
    "            per_example_step_seed, num=4)\n",
    "        image = tf.image.stateless_random_crop(\n",
    "            image,\n",
    "            (image_shape[0], image_shape[0], 3),\n",
    "            seed=per_example_step_seeds[0])\n",
    "        image = tf.image.stateless_random_flip_left_right(\n",
    "            image,\n",
    "            seed=per_example_step_seeds[1])\n",
    "\n",
    "        # Only random augment for now.\n",
    "        if self._aug_params.get('random_augment', False):\n",
    "          count = self._aug_params['aug_count']\n",
    "          augment_seeds = tf.random.experimental.stateless_split(\n",
    "              per_example_step_seeds[2], num=count)\n",
    "          augmenter = augment_utils.RandAugment()\n",
    "          augmented = [\n",
    "              augmenter.distort(image, seed=augment_seeds[c])\n",
    "              for c in range(count)\n",
    "          ]\n",
    "          image = tf.stack(augmented)\n",
    "\n",
    "        if use_augmix:\n",
    "          augmenter = augment_utils.RandAugment()\n",
    "          image = augmix.do_augmix(\n",
    "              image, self._aug_params, augmenter, image_dtype,\n",
    "              mean=CIFAR10_MEAN, std=CIFAR10_STD,\n",
    "              seed=per_example_step_seeds[3])\n",
    "\n",
    "      # The image has values in the range [0, 1].\n",
    "      # Optionally normalize by the dataset statistics.\n",
    "      if not use_augmix:\n",
    "        if self._normalize:\n",
    "          image = augmix.normalize_convert_image(\n",
    "              image, image_dtype, mean=CIFAR10_MEAN, std=CIFAR10_STD)\n",
    "        else:\n",
    "          image = tf.image.convert_image_dtype(image, image_dtype)\n",
    "      parsed_example = example.copy()\n",
    "      parsed_example['features'] = image\n",
    "\n",
    "      # Note that labels are always float32, even when images are bfloat16.\n",
    "      mixup_alpha = self._aug_params.get('mixup_alpha', 0)\n",
    "      label_smoothing = self._aug_params.get('label_smoothing', 0.)\n",
    "      should_onehot = mixup_alpha > 0 or label_smoothing > 0\n",
    "      if should_onehot:\n",
    "        parsed_example['labels'] = tf.one_hot(\n",
    "            example['label'], 10, dtype=tf.float32)\n",
    "      else:\n",
    "        parsed_example['labels'] = tf.cast(example['label'], tf.float32)\n",
    "\n",
    "      del parsed_example['image']\n",
    "      del parsed_example['label']\n",
    "      return parsed_example\n",
    "\n",
    "    return _example_parser\n",
    "\n",
    "  def _create_process_batch_fn(\n",
    "      self,\n",
    "      batch_size: int) -> Optional[base.PreProcessFn]:\n",
    "    if self._is_training and self._aug_params.get('mixup_alpha', 0) > 0:\n",
    "      if self._adaptive_mixup:\n",
    "        return _tuple_dict_fn_converter(\n",
    "            augmix.adaptive_mixup, batch_size, self._aug_params)\n",
    "      else:\n",
    "        return _tuple_dict_fn_converter(\n",
    "            augmix.mixup, batch_size, self._aug_params)\n",
    "    return None\n",
    "\n",
    "\n",
    "class Cifar10Dataset(_CifarDataset):\n",
    "  \"\"\"CIFAR10 dataset builder class.\"\"\"\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    super(Cifar10Dataset, self).__init__(\n",
    "        name='cifar10',\n",
    "        fingerprint_key='id',\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class Cifar100Dataset(_CifarDataset):\n",
    "  \"\"\"CIFAR100 dataset builder class.\"\"\"\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    super(Cifar100Dataset, self).__init__(\n",
    "        name='cifar100',\n",
    "        fingerprint_key='id',\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class Cifar10CorruptedDataset(_CifarDataset):\n",
    "  \"\"\"CIFAR10-C dataset builder class.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      corruption_type: str,\n",
    "      severity: int,\n",
    "      **kwargs):\n",
    "    \"\"\"Create a CIFAR10-C tf.data.Dataset builder.\n",
    "    Args:\n",
    "      corruption_type: Corruption name.\n",
    "      severity: Corruption severity, an integer between 1 and 5.\n",
    "      **kwargs: Additional keyword arguments.\n",
    "    \"\"\"\n",
    "    super(Cifar10CorruptedDataset, self).__init__(\n",
    "        name=f'cifar10_corrupted/{corruption_type}_{severity}',\n",
    "        fingerprint_key=None,\n",
    "        **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKR3NGUEcyQm"
   },
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1623683217043,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "iV-aaJyuacx1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5350e1090691>:53: UserWarning: Skipped due to ImportError: No module named 'librosa'\n",
      "  warnings.warn(f'Skipped due to ImportError: {e}')\n"
     ]
    }
   ],
   "source": [
    "#datasets\n",
    "\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\"\"\"Dataset getter utility.\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from typing import Any, List, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from uncertainty_baselines.datasets.base import BaseDataset\n",
    "from uncertainty_baselines.datasets.cifar import Cifar100Dataset\n",
    "from uncertainty_baselines.datasets.cifar import Cifar10CorruptedDataset\n",
    "#from uncertainty_baselines.datasets.cifar import Cifar10Dataset\n",
    "from uncertainty_baselines.datasets.cifar100_corrupted import Cifar100CorruptedDataset\n",
    "from uncertainty_baselines.datasets.clinc_intent import ClincIntentDetectionDataset\n",
    "from uncertainty_baselines.datasets.criteo import CriteoDataset\n",
    "from uncertainty_baselines.datasets.diabetic_retinopathy_detection import DiabeticRetinopathyDetectionDataset\n",
    "from uncertainty_baselines.datasets.genomics_ood import GenomicsOodDataset\n",
    "from uncertainty_baselines.datasets.glue import GlueDatasets\n",
    "from uncertainty_baselines.datasets.imagenet import ImageNetDataset\n",
    "from uncertainty_baselines.datasets.mnist import MnistDataset\n",
    "from uncertainty_baselines.datasets.mnli import MnliDataset\n",
    "from uncertainty_baselines.datasets.movielens import MovieLensDataset\n",
    "from uncertainty_baselines.datasets.places import Places365Dataset\n",
    "from uncertainty_baselines.datasets.random import RandomGaussianImageDataset\n",
    "from uncertainty_baselines.datasets.random import RandomRademacherImageDataset\n",
    "from uncertainty_baselines.datasets.svhn import SvhnDataset\n",
    "from uncertainty_baselines.datasets.toxic_comments import CivilCommentsDataset\n",
    "from uncertainty_baselines.datasets.toxic_comments import CivilCommentsIdentitiesDataset\n",
    "from uncertainty_baselines.datasets.toxic_comments import WikipediaToxicityDataset\n",
    "\n",
    "try:\n",
    "  from uncertainty_baselines.datasets.speech_commands import SpeechCommandsDataset  # pylint: disable=g-import-not-at-top\n",
    "except ImportError as e:\n",
    "  warnings.warn(f'Skipped due to ImportError: {e}')\n",
    "  SpeechCommandsDataset = None\n",
    "\n",
    "DATASETS = {\n",
    "    'cifar100': Cifar100Dataset,\n",
    "    'cifar10': Cifar10Dataset,\n",
    "    'cifar10_corrupted': Cifar10CorruptedDataset,\n",
    "    'cifar100_corrupted': Cifar100CorruptedDataset,\n",
    "    'civil_comments': CivilCommentsDataset,\n",
    "    'civil_comments_identities': CivilCommentsIdentitiesDataset,\n",
    "    'clinic_intent': ClincIntentDetectionDataset,\n",
    "    'criteo': CriteoDataset,\n",
    "    'diabetic_retinopathy_detection': DiabeticRetinopathyDetectionDataset,\n",
    "    'imagenet': ImageNetDataset,\n",
    "    'mnist': MnistDataset,\n",
    "    'mnli': MnliDataset,\n",
    "    'movielens': MovieLensDataset,\n",
    "    'places365': Places365Dataset,\n",
    "    'random_gaussian': RandomGaussianImageDataset,\n",
    "    'random_rademacher': RandomRademacherImageDataset,\n",
    "    'speech_commands': SpeechCommandsDataset,\n",
    "    'svhn_cropped': SvhnDataset,\n",
    "    'glue/cola': GlueDatasets['glue/cola'],\n",
    "    'glue/sst2': GlueDatasets['glue/sst2'],\n",
    "    'glue/mrpc': GlueDatasets['glue/mrpc'],\n",
    "    'glue/qqp': GlueDatasets['glue/qqp'],\n",
    "    'glue/qnli': GlueDatasets['glue/qnli'],\n",
    "    'glue/rte': GlueDatasets['glue/rte'],\n",
    "    'glue/wnli': GlueDatasets['glue/wnli'],\n",
    "    'glue/stsb': GlueDatasets['glue/stsb'],\n",
    "    'wikipedia_toxicity': WikipediaToxicityDataset,\n",
    "    'genomics_ood': GenomicsOodDataset,\n",
    "}\n",
    "\n",
    "\n",
    "def get_dataset_names() -> List[str]:\n",
    "  return list(DATASETS.keys())\n",
    "\n",
    "\n",
    "def get(\n",
    "    dataset_name: str,\n",
    "    split: Union[Tuple[str, float], str, tfds.Split],\n",
    "    **hyperparameters: Any) -> BaseDataset:\n",
    "  \"\"\"Gets a dataset builder by name.\n",
    "  Note that the user still needs to call\n",
    "  `distribution_strategy.experimental_distribute_dataset(dataset)` on the loaded\n",
    "  dataset if they are running in a distributed environment.\n",
    "  Args:\n",
    "    dataset_name: Name of the dataset builder class.\n",
    "    split: a dataset split, either a custom tfds.Split or one of the\n",
    "      tfds.Split enums [TRAIN, VALIDAITON, TEST] or their lowercase string\n",
    "      names.\n",
    "    **hyperparameters: dict of possible kwargs to be passed to the dataset\n",
    "      constructor.\n",
    "  Returns:\n",
    "    A dataset builder class with a method .build(split) which can be called to\n",
    "    get the tf.data.Dataset, which has elements that are a dict described by\n",
    "    dataset_builder.info.\n",
    "  Raises:\n",
    "    ValueError: If dataset_name is unrecognized.\n",
    "  \"\"\"\n",
    "  hyperparameters_py = {\n",
    "      k: (v.numpy().tolist() if isinstance(v, tf.Tensor) else v)\n",
    "      for k, v in hyperparameters.items()\n",
    "  }\n",
    "  logging.info(\n",
    "      'Building dataset %s with additional kwargs:\\n%s',\n",
    "      dataset_name,\n",
    "      json.dumps(hyperparameters_py, indent=2, sort_keys=True))\n",
    "  if dataset_name not in DATASETS:\n",
    "    raise ValueError('Unrecognized dataset name: {!r}'.format(dataset_name))\n",
    "\n",
    "  dataset_class = DATASETS[dataset_name]\n",
    "  return dataset_class(\n",
    "      split=split,\n",
    "      **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203,
     "referenced_widgets": [
      "8a3bce89d8a24cec891c97d2de3da92c",
      "d82660b384554df2be06fb8eca3891f8",
      "3a176013226d444c83f74a67305edbab",
      "e1e124875c05440fb2668ddd04514954",
      "0a8216fa497f4fadacac97aa33a2882e",
      "3f905702355748eea3e837373b426ef9",
      "5a3694e29d3348bf98ccde5fab5851a7",
      "88ed94bff0dc47dc9078cec2fe8c5ff5",
      "4f5591d79e484d138dcf36fdcc8a9676",
      "cbacbb95817f439388978a200ebc68c3",
      "3f31784765414b89b1fdc5329520d51c",
      "a8edc03628a64bf29446f21fce1114f0",
      "fee5c32e94b24a5a824735017a36e4d2",
      "00b6f21dd98c4010a5edbcf8efa42bad",
      "f54a480c69b646d092aa13172f053bd3",
      "35dd98803513440bb0945480b8841391",
      "58d2d47de219479db56d0b0ce0f5e688",
      "5823097ee6d64ab59812f07f827db710",
      "71200e204bd7409ab0d16eeeeaa0e23f",
      "a96fa29b26d84bff9203d67315f56d51",
      "6bbfe2bb9caf4968b51255b63e5910a1",
      "085273ecdacb4a939b242fa7fa0c8a71",
      "2434b90fef484b728ba9c5a8635f8275",
      "844016ae0da64336bd5a144a9165737a",
      "5c0565b82d754396925fb74ad45936fb",
      "e9003f4087154331b3d3827e2b243ee3",
      "4594dc94e8d04af9a8cbe9ede5a9af09",
      "9f5275d80c0e4c6e9184ef0888c08495",
      "a7bc73eab1a1455eb4ee136cc9b46a85",
      "08611fe2c829430280a371a8e674f4f7",
      "9f967a3261494499823c584c5944b3d2",
      "e7aded977c194dcaa58bbdb4332c1c7b",
      "4ccfc511845845acac04cf0acce42d45",
      "e7d002292d904b70bd85dcec30b46a5d",
      "e4b357eace854aa19215be43cb922442",
      "ef6a35f10f254d37a270cae1f48e1e53",
      "c572993a4a8d48ea91f67a01510ff652",
      "8929537d061c4ac69110c7862927e4dd",
      "3554575f38b641069c956b3dead472f2",
      "eee8f17f26e342a49f485fd673fb0487",
      "28d3a7201f264748aef2d66b7266b06f",
      "7852f0aec1a447b39044d4a945a6b061",
      "3dd2341ae4064b8a8c20b660b4be518f",
      "bf5fdebd801949d8ac62d42335dc0b21",
      "0031b670d8e447c1ad8230eb2ce303d2",
      "cfff4c3d52284b91963b46e3b704b3e6",
      "4bb40d9c66fe4936a02eb2bc330edac1",
      "e97b2c453b0b4384a78a2dbfeb8035af",
      "bc4e74d45ce14cc1af0d6dffdc375141",
      "8d1f5838cf43466fbf6056d8ba1292ef",
      "d3278b6950934cd98656e60ab5337a6a",
      "cdb3d3b635d84a51b5e7381e6033b2e0",
      "579f864dc6804738b4e98e4907f2625d",
      "acf93c4686d44b96b54020e73b30168a",
      "f8f8493ce29e4057a205d33a1e6da541",
      "35d03895fcec4c5caf7a8289299373ed",
      "1b618dbf37304f54a76244595c354de7",
      "3bfd5704f76140dd98515461bc3048e0",
      "c69e4bc3a37d4724b77d978eeddaa23c",
      "aa79990886cf444b8b77775b991e26e7",
      "9512c2e067b74913b3a1934595bac0d7",
      "b57c2622081c4402af2c6b1745beddd1",
      "61f8b0fbd56643de9561022695ff17e0",
      "af95fa47862a4d28a2e63591a00f6a91"
     ]
    },
    "executionInfo": {
     "elapsed": 42543,
     "status": "ok",
     "timestamp": 1623683259579,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "_rWVYr4WgNAU",
    "outputId": "62166a8a-bcd8-47f4-f7b2-569fbac9c82e"
   },
   "outputs": [],
   "source": [
    "dataset_builder = tfds.builder('cifar10')\n",
    "dataset_builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l20R8Qegh9a-"
   },
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1623683260008,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "uLoqWHV1h6BZ"
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\"\"\"Wide Residual Network.\"\"\"\n",
    "\n",
    "import functools\n",
    "from typing import Any, Dict, Iterable, Optional\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "HP_KEYS = ('bn_l2', 'input_conv_l2', 'group_1_conv_l2', 'group_2_conv_l2',\n",
    "           'group_3_conv_l2', 'dense_kernel_l2', 'dense_bias_l2')\n",
    "\n",
    "BatchNormalization = functools.partial(  # pylint: disable=invalid-name\n",
    "    tf.keras.layers.BatchNormalization,\n",
    "    epsilon=1e-5,  # using epsilon and momentum defaults from Torch\n",
    "    momentum=0.9)\n",
    "\n",
    "\n",
    "def Conv2D(filters, seed=None, **kwargs):  # pylint: disable=invalid-name\n",
    "  \"\"\"Conv2D layer that is deterministically initialized.\"\"\"\n",
    "  default_kwargs = {\n",
    "      'kernel_size': 3,\n",
    "      'padding': 'same',\n",
    "      'use_bias': False,\n",
    "      # Note that we need to use the class constructor for the initializer to\n",
    "      # get deterministic initialization.\n",
    "      'kernel_initializer': tf.keras.initializers.HeNormal(seed=seed),\n",
    "  }\n",
    "  # Override defaults with the passed kwargs.\n",
    "  default_kwargs.update(kwargs)\n",
    "  return tf.keras.layers.Conv2D(filters, **default_kwargs)\n",
    "\n",
    "\n",
    "def basic_block(\n",
    "    inputs: tf.Tensor,\n",
    "    filters: int,\n",
    "    strides: int,\n",
    "    conv_l2: float,\n",
    "    bn_l2: float,\n",
    "    seed: int,\n",
    "    version: int) -> tf.Tensor:\n",
    "  \"\"\"Basic residual block of two 3x3 convs.\n",
    "  Args:\n",
    "    inputs: tf.Tensor.\n",
    "    filters: Number of filters for Conv2D.\n",
    "    strides: Stride dimensions for Conv2D.\n",
    "    conv_l2: L2 regularization coefficient for the conv kernels.\n",
    "    bn_l2: L2 regularization coefficient for the batch norm layers.\n",
    "    seed: random seed used for initialization.\n",
    "    version: 1, indicating the original ordering from He et al. (2015); or 2,\n",
    "      indicating the preactivation ordering from He et al. (2016).\n",
    "  Returns:\n",
    "    tf.Tensor.\n",
    "  \"\"\"\n",
    "  x = inputs\n",
    "  y = inputs\n",
    "  if version == 2:\n",
    "    y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                           gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "    y = tf.keras.layers.Activation('relu')(y)\n",
    "  seeds = tf.random.experimental.stateless_split([seed, seed + 1], 3)[:, 0]\n",
    "  y = Conv2D(filters,\n",
    "             strides=strides,\n",
    "             seed=seeds[0],\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(y)\n",
    "  y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                         gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "  y = tf.keras.layers.Activation('relu')(y)\n",
    "  y = Conv2D(filters,\n",
    "             strides=1,\n",
    "             seed=seeds[1],\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(y)\n",
    "  if version == 1:\n",
    "    y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                           gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "  if not x.shape.is_compatible_with(y.shape):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size=1,\n",
    "               strides=strides,\n",
    "               seed=seeds[2],\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(x)\n",
    "  x = tf.keras.layers.add([x, y])\n",
    "  if version == 1:\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "def group(inputs, filters, strides, num_blocks, conv_l2, bn_l2, version, seed):\n",
    "  \"\"\"Group of residual blocks.\"\"\"\n",
    "  seeds = tf.random.experimental.stateless_split(\n",
    "      [seed, seed + 1], num_blocks)[:, 0]\n",
    "  x = basic_block(\n",
    "      inputs,\n",
    "      filters=filters,\n",
    "      strides=strides,\n",
    "      conv_l2=conv_l2,\n",
    "      bn_l2=bn_l2,\n",
    "      version=version,\n",
    "      seed=seeds[0])\n",
    "  for i in range(num_blocks - 1):\n",
    "    x = basic_block(\n",
    "        x,\n",
    "        filters=filters,\n",
    "        strides=1,\n",
    "        conv_l2=conv_l2,\n",
    "        bn_l2=bn_l2,\n",
    "        version=version,\n",
    "        seed=seeds[i + 1])\n",
    "  return x\n",
    "\n",
    "\n",
    "def _parse_hyperparameters(l2: float, hps: Dict[str, float]):\n",
    "  \"\"\"Extract the L2 parameters for the dense, conv and batch-norm layers.\"\"\"\n",
    "\n",
    "  assert_msg = ('Ambiguous hyperparameter specifications: either l2 or hps '\n",
    "                'must be provided (received {} and {}).'.format(l2, hps))\n",
    "  is_specified = lambda h: bool(h) and all(v is not None for v in h.values())\n",
    "  only_l2_is_specified = l2 is not None and not is_specified(hps)\n",
    "  only_hps_is_specified = l2 is None and is_specified(hps)\n",
    "  assert only_l2_is_specified or only_hps_is_specified, assert_msg\n",
    "  if only_hps_is_specified:\n",
    "    assert_msg = 'hps must contain the keys {}!={}.'.format(HP_KEYS, hps.keys())\n",
    "    assert set(hps.keys()).issuperset(HP_KEYS), assert_msg\n",
    "    return hps\n",
    "  else:\n",
    "    return {k: l2 for k in HP_KEYS}\n",
    "\n",
    "\n",
    "def wide_resnet(\n",
    "    input_shape: Iterable[int],\n",
    "    depth: int,\n",
    "    width_multiplier: int,\n",
    "    num_classes: int,\n",
    "    l2: float,\n",
    "    version: int = 2,\n",
    "    seed: int = 42,\n",
    "    hps: Optional[Dict[str, float]] = None) -> tf.keras.models.Model:\n",
    "  \"\"\"Builds Wide ResNet.\n",
    "  Following Zagoruyko and Komodakis (2016), it accepts a width multiplier on the\n",
    "  number of filters. Using three groups of residual blocks, the network maps\n",
    "  spatial features of size 32x32 -> 16x16 -> 8x8.\n",
    "  Args:\n",
    "    input_shape: tf.Tensor.\n",
    "    depth: Total number of convolutional layers. \"n\" in WRN-n-k. It differs from\n",
    "      He et al. (2015)'s notation which uses the maximum depth of the network\n",
    "      counting non-conv layers like dense.\n",
    "    width_multiplier: Integer to multiply the number of typical filters by. \"k\"\n",
    "      in WRN-n-k.\n",
    "    num_classes: Number of output classes.\n",
    "    l2: L2 regularization coefficient.\n",
    "    version: 1, indicating the original ordering from He et al. (2015); or 2,\n",
    "      indicating the preactivation ordering from He et al. (2016).\n",
    "    seed: random seed used for initialization.\n",
    "    hps: Fine-grained specs of the hyperparameters, as a Dict[str, float].\n",
    "  Returns:\n",
    "    tf.keras.Model.\n",
    "  \"\"\"\n",
    "  l2_reg = tf.keras.regularizers.l2\n",
    "  hps = _parse_hyperparameters(l2, hps)\n",
    "\n",
    "  seeds = tf.random.experimental.stateless_split([seed, seed + 1], 5)[:, 0]\n",
    "  if (depth - 4) % 6 != 0:\n",
    "    raise ValueError('depth should be 6n+4 (e.g., 16, 22, 28, 40).')\n",
    "  num_blocks = (depth - 4) // 6\n",
    "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "  x = Conv2D(16,\n",
    "             strides=1,\n",
    "             seed=seeds[0],\n",
    "             kernel_regularizer=l2_reg(hps['input_conv_l2']))(inputs)\n",
    "  if version == 1:\n",
    "    x = BatchNormalization(beta_regularizer=l2_reg(hps['bn_l2']),\n",
    "                           gamma_regularizer=l2_reg(hps['bn_l2']))(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = group(x,\n",
    "            filters=16 * width_multiplier,\n",
    "            strides=1,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_1_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[1])\n",
    "  x = group(x,\n",
    "            filters=32 * width_multiplier,\n",
    "            strides=2,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_2_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[2])\n",
    "  x = group(x,\n",
    "            filters=64 * width_multiplier,\n",
    "            strides=2,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_3_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[3])\n",
    "  if version == 2:\n",
    "    x = BatchNormalization(beta_regularizer=l2_reg(hps['bn_l2']),\n",
    "                           gamma_regularizer=l2_reg(hps['bn_l2']))(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=tf.keras.initializers.HeNormal(seed=seeds[4]),\n",
    "      kernel_regularizer=l2_reg(hps['dense_kernel_l2']),\n",
    "      bias_regularizer=l2_reg(hps['dense_bias_l2']))(x)\n",
    "  return tf.keras.Model(\n",
    "      inputs=inputs,\n",
    "      outputs=x,\n",
    "      name='wide_resnet-{}-{}'.format(depth, width_multiplier))\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    batch_size: Optional[int],\n",
    "    depth: int,\n",
    "    width_multiplier: int,\n",
    "    input_shape: Iterable[int] = (32, 32, 3),\n",
    "    num_classes: int = 10,\n",
    "    l2_weight: float = 0.0,\n",
    "    version: int = 2,\n",
    "    **unused_kwargs: Dict[str, Any]) -> tf.keras.models.Model:\n",
    "  \"\"\"Creates model.\"\"\"\n",
    "  del batch_size  # unused arg\n",
    "  return wide_resnet(input_shape=input_shape,\n",
    "                     depth=depth,\n",
    "                     width_multiplier=width_multiplier,\n",
    "                     num_classes=num_classes,\n",
    "                     l2=l2_weight,\n",
    "                     version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623683260009,
     "user": {
      "displayName": "­김덕성 | 서울 산업공학과",
      "photoUrl": "",
      "userId": "15126471116977583172"
     },
     "user_tz": -540
    },
    "id": "9gVUYU9qlcOw"
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#     print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "# except ValueError:\n",
    "#     tpu = None\n",
    "\n",
    "# if tpu:\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# else:\n",
    "#     strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB84Bamhc2q_"
   },
   "source": [
    "# 중요코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXZqqQgFXWH7",
    "outputId": "2f8ae935-bdc7-4fff-a902-e89a88e3bded"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 01:09:41.154202 25832 <ipython-input-15-0564270d6ae3>:103] [<ipython-input-15-0564270d6ae3>:103] Saving checkpoints at D:\\test3\n",
      "I0615 01:09:41.157200 25832 dataset_info.py:365] [dataset_info.py:365] Load dataset info from C:\\Users\\김문환\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0615 01:09:41.162203 25832 <ipython-input-15-0564270d6ae3>:114] [<ipython-input-15-0564270d6ae3>:114] Steps per epoch 97\n",
      "I0615 01:09:41.163203 25832 <ipython-input-15-0564270d6ae3>:115] [<ipython-input-15-0564270d6ae3>:115] Size of the dataset 50000\n",
      "I0615 01:09:41.164200 25832 <ipython-input-15-0564270d6ae3>:116] [<ipython-input-15-0564270d6ae3>:116] Train proportion 1.0\n",
      "I0615 01:09:41.184203 25832 <ipython-input-11-5350e1090691>:118] [<ipython-input-11-5350e1090691>:118] Building dataset cifar10 with additional kwargs:\n",
      "{\n",
      "  \"aug_params\": {\n",
      "    \"aug_count\": 1,\n",
      "    \"augmix\": false,\n",
      "    \"augmix_depth\": -1,\n",
      "    \"augmix_prob_coeff\": 0.5,\n",
      "    \"augmix_width\": 3\n",
      "  },\n",
      "  \"data_dir\": null,\n",
      "  \"download_data\": false,\n",
      "  \"seed\": 1769886085,\n",
      "  \"validation_percent\": 0.0\n",
      "}\n",
      "I0615 01:09:41.187200 25832 dataset_info.py:365] [dataset_info.py:365] Load dataset info from C:\\Users\\김문환\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0615 01:09:41.197209 25832 logging_logger.py:33] [logging_logger.py:33] Constructing tf.data.Dataset cifar10 for split train, from C:\\Users\\김문환\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0615 01:09:42.325202 25832 <ipython-input-11-5350e1090691>:118] [<ipython-input-11-5350e1090691>:118] Building dataset cifar10 with additional kwargs:\n",
      "{\n",
      "  \"data_dir\": null\n",
      "}\n",
      "I0615 01:09:42.328204 25832 dataset_info.py:365] [dataset_info.py:365] Load dataset info from C:\\Users\\김문환\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0615 01:09:42.334199 25832 logging_logger.py:33] [logging_logger.py:33] Constructing tf.data.Dataset cifar10 for split test, from C:\\Users\\김문환\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0615 01:09:42.432204 25832 <ipython-input-15-0564270d6ae3>:182] [<ipython-input-15-0564270d6ae3>:182] Building ResNet model\n",
      "I0615 01:09:43.681203 25832 <ipython-input-15-0564270d6ae3>:191] [<ipython-input-15-0564270d6ae3>:191] Model input shape: (None, 32, 32, 3)\n",
      "I0615 01:09:43.682201 25832 <ipython-input-15-0564270d6ae3>:192] [<ipython-input-15-0564270d6ae3>:192] Model output shape: (None, 10)\n",
      "I0615 01:09:43.688203 25832 <ipython-input-15-0564270d6ae3>:193] [<ipython-input-15-0564270d6ae3>:193] Model number of weights: 36497146\n",
      "I0615 01:09:43.916203 25832 <ipython-input-15-0564270d6ae3>:357] [<ipython-input-15-0564270d6ae3>:357] Starting to run epoch: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Wide ResNet 28-10 on CIFAR-10/100 trained with maximum likelihood.\n",
    "Hyperparameters differ slightly from the original paper's code\n",
    "(https://github.com/szagoruyko/wide-residual-networks) as TensorFlow uses, for\n",
    "example, l2 instead of weight decay, and a different parameterization for SGD's\n",
    "momentum.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import robustness_metrics as rm\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import uncertainty_baselines as ub\n",
    "#import utils  # local file import\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "#flags.DEFINE_string(\"f\", \"\", \"kernel\")\n",
    "flags.DEFINE_float('label_smoothing', 0., 'Label smoothing parameter in [0,1].')\n",
    "flags.register_validator('label_smoothing',\n",
    "                         lambda ls: ls >= 0.0 and ls <= 1.0,\n",
    "                         message='--label_smoothing must be in [0, 1].')\n",
    "\n",
    "# Data Augmentation flags.\n",
    "flags.DEFINE_bool('augmix', False,\n",
    "                  'Whether to perform AugMix [4] on the input data.')\n",
    "flags.DEFINE_integer('aug_count', 1,\n",
    "                     'Number of augmentation operations in AugMix to perform '\n",
    "                     'on the input image. In the simgle model context, it'\n",
    "                     'should be 1. In the ensembles context, it should be'\n",
    "                     'ensemble_size if we perform random_augment only; It'\n",
    "                     'should be (ensemble_size - 1) if we perform augmix.')\n",
    "flags.DEFINE_float('augmix_prob_coeff', 0.5, 'Augmix probability coefficient.')\n",
    "flags.DEFINE_integer('augmix_depth', -1,\n",
    "                     'Augmix depth, -1 meaning sampled depth. This corresponds'\n",
    "                     'to line 7 in the Algorithm box in [4].')\n",
    "flags.DEFINE_integer('augmix_width', 3,\n",
    "                     'Augmix width. This corresponds to the k in line 5 in the'\n",
    "                     'Algorithm box in [4].')\n",
    "\n",
    "# Fine-grained specification of the hyperparameters (used when FLAGS.l2 is None)\n",
    "flags.DEFINE_float('bn_l2', None, 'L2 reg. coefficient for batch-norm layers.')\n",
    "flags.DEFINE_float('input_conv_l2', None,\n",
    "                   'L2 reg. coefficient for the input conv layer.')\n",
    "flags.DEFINE_float('group_1_conv_l2', None,\n",
    "                   'L2 reg. coefficient for the 1st group of conv layers.')\n",
    "flags.DEFINE_float('group_2_conv_l2', None,\n",
    "                   'L2 reg. coefficient for the 2nd group of conv layers.')\n",
    "flags.DEFINE_float('group_3_conv_l2', None,\n",
    "                   'L2 reg. coefficient for the 3rd group of conv layers.')\n",
    "flags.DEFINE_float('dense_kernel_l2', None,\n",
    "                   'L2 reg. coefficient for the kernel of the dense layer.')\n",
    "flags.DEFINE_float('dense_bias_l2', None,\n",
    "                   'L2 reg. coefficient for the bias of the dense layer.')\n",
    "\n",
    "\n",
    "flags.DEFINE_bool('collect_profile', False,\n",
    "                  'Whether to trace a profile with tensorboard')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def _extract_hyperparameter_dictionary():\n",
    "  \"\"\"Create the dictionary of hyperparameters from FLAGS.\"\"\"\n",
    "  flags_as_dict = FLAGS.flag_values_dict()\n",
    "  hp_keys = ub.models.models.wide_resnet.HP_KEYS\n",
    "  hps = {k: flags_as_dict[k] for k in hp_keys}\n",
    "  return hps\n",
    "\n",
    "def _extract_hyperparameter_dictionary():\n",
    "  \"\"\"Create the dictionary of hyperparameters from FLAGS.\"\"\"\n",
    "  hp_keys = ('bn_l2', 'input_conv_l2', 'group_1_conv_l2', 'group_2_conv_l2',\n",
    "           'group_3_conv_l2', 'dense_kernel_l2', 'dense_bias_l2')\n",
    "  hps = {'bn_l2':None, 'input_conv_l2':None, 'group_1_conv_l2':None, 'group_2_conv_l2':None,\n",
    "           'group_3_conv_l2':None, 'dense_kernel_l2':None, 'dense_bias_l2':None}\n",
    "  return hps  \n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  fmt = '[%(filename)s:%(lineno)s] %(message)s'\n",
    "  formatter = logging.PythonFormatter(fmt)\n",
    "  logging.get_absl_handler().setFormatter(formatter)\n",
    "  del argv  # unused arg\n",
    "\n",
    "  tf.io.gfile.makedirs(FLAGS.output_dir)\n",
    "  logging.info('Saving checkpoints at %s', FLAGS.output_dir)\n",
    "  tf.random.set_seed(FLAGS.seed)\n",
    "\n",
    "  data_dir = None\n",
    "  \n",
    "\n",
    "  ds_info = tfds.builder(FLAGS.dataset).info\n",
    "  batch_size = FLAGS.per_core_batch_size * FLAGS.num_cores\n",
    "  train_dataset_size = (\n",
    "      ds_info.splits['train'].num_examples * FLAGS.train_proportion)\n",
    "  steps_per_epoch = int(train_dataset_size / batch_size)\n",
    "  logging.info('Steps per epoch %s', steps_per_epoch)\n",
    "  logging.info('Size of the dataset %s', ds_info.splits['train'].num_examples)\n",
    "  logging.info('Train proportion %s', FLAGS.train_proportion)\n",
    "  steps_per_eval = ds_info.splits['test'].num_examples // batch_size\n",
    "  num_classes = ds_info.features['label'].num_classes\n",
    "\n",
    "  aug_params = {\n",
    "      'augmix': FLAGS.augmix,\n",
    "      'aug_count': FLAGS.aug_count,\n",
    "      'augmix_depth': FLAGS.augmix_depth,\n",
    "      'augmix_prob_coeff': FLAGS.augmix_prob_coeff,\n",
    "      'augmix_width': FLAGS.augmix_width,\n",
    "  }\n",
    "\n",
    "  # Note that stateless_{fold_in,split} may incur a performance cost, but a\n",
    "  # quick side-by-side test seemed to imply this was minimal.\n",
    "\n",
    "  seeds = tf.random.experimental.stateless_split(\n",
    "      [FLAGS.seed, FLAGS.seed + 1], 2)[:, 0]\n",
    "  train_builder = get(\n",
    "      FLAGS.dataset,\n",
    "      data_dir=data_dir,\n",
    "      download_data=FLAGS.download_data,\n",
    "      split=tfds.Split.TRAIN,\n",
    "      seed=seeds[0],\n",
    "      aug_params=aug_params,\n",
    "      validation_percent=1. - FLAGS.train_proportion,)\n",
    "  train_dataset = train_builder.load(batch_size=batch_size)\n",
    "  validation_dataset = None\n",
    "  steps_per_validation = 0\n",
    "  if FLAGS.train_proportion < 1.0:\n",
    "    validation_builder = get(\n",
    "        FLAGS.dataset,\n",
    "        split=tfds.Split.VALIDATION,\n",
    "        validation_percent=1. - FLAGS.train_proportion,\n",
    "        data_dir=data_dir)\n",
    "    validation_dataset = validation_builder.load(batch_size=batch_size)\n",
    "    steps_per_validation = validation_builder.num_examples // batch_size\n",
    "  clean_test_builder = get(\n",
    "      FLAGS.dataset,\n",
    "      split=tfds.Split.TEST,\n",
    "      data_dir=data_dir)\n",
    "  clean_test_dataset = clean_test_builder.load(batch_size=batch_size)\n",
    "  test_datasets = {\n",
    "      'clean': clean_test_dataset,\n",
    "  }\n",
    "  #test_datasets=clean_test_dataset\n",
    "\n",
    "  steps_per_epoch = train_builder.num_examples // batch_size\n",
    "  steps_per_eval = clean_test_builder.num_examples // batch_size\n",
    "  num_classes = 100 if FLAGS.dataset == 'cifar100' else 10\n",
    "  if FLAGS.corruptions_interval > 0:\n",
    "    if FLAGS.dataset == 'cifar100':\n",
    "      data_dir = FLAGS.cifar100_c_path\n",
    "    corruption_types, _ = load_corrupted_test_info(FLAGS.dataset)\n",
    "    for corruption_type in corruption_types:\n",
    "      for severity in range(1, 6):\n",
    "        dataset = get(\n",
    "            f'{FLAGS.dataset}_corrupted',\n",
    "            corruption_type=corruption_type,\n",
    "            severity=severity,\n",
    "            split=tfds.Split.TEST,\n",
    "            data_dir=data_dir).load(batch_size=batch_size)\n",
    "\n",
    "\n",
    "  summary_writer = tf.summary.create_file_writer(\n",
    "      os.path.join(FLAGS.output_dir, 'summaries'))\n",
    "\n",
    "  logging.info('Building ResNet model')\n",
    "  model = wide_resnet(\n",
    "      input_shape=(32, 32, 3),\n",
    "      depth=28,\n",
    "      width_multiplier=10,\n",
    "      num_classes=num_classes,\n",
    "      l2=FLAGS.l2,\n",
    "      hps=_extract_hyperparameter_dictionary(),\n",
    "      seed=seeds[1])\n",
    "  logging.info('Model input shape: %s', model.input_shape)\n",
    "  logging.info('Model output shape: %s', model.output_shape)\n",
    "  logging.info('Model number of weights: %s', model.count_params())\n",
    "  # Linearly scale learning rate and the decay epochs by vanilla settings.\n",
    "  base_lr = FLAGS.base_learning_rate * batch_size / 128\n",
    "  lr_decay_epochs = [(int(start_epoch_str) * FLAGS.train_epochs) // 200\n",
    "                      for start_epoch_str in FLAGS.lr_decay_epochs]\n",
    "  lr_schedule = ub.schedules.WarmUpPiecewiseConstantSchedule(\n",
    "      steps_per_epoch,\n",
    "      base_lr,\n",
    "      decay_ratio=FLAGS.lr_decay_ratio,\n",
    "      decay_epochs=lr_decay_epochs,\n",
    "      warmup_epochs=FLAGS.lr_warmup_epochs)\n",
    "  optimizer = tf.keras.optimizers.SGD(lr_schedule,\n",
    "                                      momentum=1.0 - FLAGS.one_minus_momentum,\n",
    "                                      nesterov=True)\n",
    "  metrics = {\n",
    "      'train/negative_log_likelihood':\n",
    "          tf.keras.metrics.Mean(),\n",
    "      'train/accuracy':\n",
    "          tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "      'train/loss':\n",
    "          tf.keras.metrics.Mean(),\n",
    "      'train/ece':\n",
    "          rm.metrics.ExpectedCalibrationError(num_bins=FLAGS.num_bins),\n",
    "      'test/negative_log_likelihood':\n",
    "          tf.keras.metrics.Mean(),\n",
    "      'test/accuracy':\n",
    "          tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "      'test/ece':\n",
    "          rm.metrics.ExpectedCalibrationError(num_bins=FLAGS.num_bins),\n",
    "  }\n",
    "  if validation_dataset:\n",
    "    metrics.update({\n",
    "        'validation/negative_log_likelihood': tf.keras.metrics.Mean(),\n",
    "        'validation/accuracy': tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        'validation/ece': rm.metrics.ExpectedCalibrationError(\n",
    "            num_bins=FLAGS.num_bins),\n",
    "    })\n",
    "  if FLAGS.corruptions_interval > 0:\n",
    "    corrupt_metrics = {}\n",
    "    for intensity in range(1, 6):\n",
    "      for corruption in corruption_types:\n",
    "        dataset_name = '{0}_{1}'.format(corruption, intensity)\n",
    "        corrupt_metrics['test/nll_{}'.format(dataset_name)] = (\n",
    "            tf.keras.metrics.Mean())\n",
    "        corrupt_metrics['test/accuracy_{}'.format(dataset_name)] = (\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy())\n",
    "        corrupt_metrics['test/ece_{}'.format(dataset_name)] = (\n",
    "            rm.metrics.ExpectedCalibrationError(num_bins=FLAGS.num_bins))\n",
    "\n",
    "  checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "  latest_checkpoint = tf.train.latest_checkpoint(FLAGS.output_dir)\n",
    "  initial_epoch = 0\n",
    "  if latest_checkpoint:\n",
    "    # checkpoint.restore must be within a strategy.scope() so that optimizer\n",
    "    # slot variables are mirrored.\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "    logging.info('Loaded checkpoint %s', latest_checkpoint)\n",
    "    initial_epoch = optimizer.iterations.numpy() // steps_per_epoch\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(iterator):\n",
    "    \"\"\"Training StepFn.\"\"\"\n",
    "    def step_fn(inputs):\n",
    "      \"\"\"Per-Replica StepFn.\"\"\"\n",
    "      images = inputs['features']\n",
    "      labels = inputs['labels']\n",
    "      print('111')\n",
    "      if FLAGS.augmix and FLAGS.aug_count >= 1:\n",
    "        # Index 0 at augmix processing is the unperturbed image.\n",
    "        # We take just 1 augmented image from the returned augmented images.\n",
    "        images = images[:, 1, ...]\n",
    "        print('222')\n",
    "      with tf.GradientTape() as tape:\n",
    "        print('333')\n",
    "        logits = model(images, training=True)\n",
    "        print('444')\n",
    "        if FLAGS.label_smoothing == 0.:\n",
    "          print('555')\n",
    "          negative_log_likelihood = tf.reduce_mean(\n",
    "              tf.keras.losses.sparse_categorical_crossentropy(labels,\n",
    "                                                              logits,\n",
    "                                                              from_logits=True))\n",
    "          print('666')\n",
    "        else:\n",
    "          print('777')\n",
    "          one_hot_labels = tf.one_hot(tf.cast(labels, tf.int32), num_classes)\n",
    "          negative_log_likelihood = tf.reduce_mean(\n",
    "              tf.keras.losses.categorical_crossentropy(\n",
    "                  one_hot_labels,\n",
    "                  logits,\n",
    "                  from_logits=True,\n",
    "                  label_smoothing=FLAGS.label_smoothing))\n",
    "        print('888')\n",
    "        l2_loss = sum(model.losses)\n",
    "        print('999')\n",
    "        loss = negative_log_likelihood + l2_loss\n",
    "        print('101010')\n",
    "        # Scale the loss given the TPUStrategy will reduce sum all gradients.\n",
    "      print('11 11 11 11 11')\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      print('12 12 12 12 12 ')\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "      print('13 13 13 13 13 ')\n",
    "\n",
    "      print('14 14 14 14 14 ')\n",
    "      probs = tf.nn.softmax(logits)\n",
    "      print('15 15 15 15 15 ')\n",
    "      metrics['train/ece'].add_batch(probs, label=labels)\n",
    "      metrics['train/loss'].update_state(loss)\n",
    "      metrics['train/negative_log_likelihood'].update_state(\n",
    "          negative_log_likelihood)\n",
    "      metrics['train/accuracy'].update_state(labels, logits)\n",
    "\n",
    "    for _ in tf.range(tf.cast(steps_per_epoch, tf.int32)): #올바른 복제본 별 데이터를 단위에 맞춰서 제공\n",
    "      #strategy.run(step_fn, args=(next(iterator),))\n",
    "      print('16 16 16 16 16 16 16')\n",
    "      step_fn(next(iterator))\n",
    "      print('17 17 17 17 17 17')\n",
    "    # print('16 16 16 16 16 16 16')\n",
    "    # step_fn(next(iterator))\n",
    "    # print('17 17 17 17 17 17')\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(iterator, dataset_split, dataset_name, num_steps):\n",
    "    \"\"\"Evaluation StepFn.\"\"\"\n",
    "    def step_fn(inputs):\n",
    "      \"\"\"Per-Replica StepFn.\"\"\"\n",
    "      images = inputs['features']\n",
    "      labels = inputs['labels']\n",
    "      logits = model(images, training=False)\n",
    "      probs = tf.nn.softmax(logits)\n",
    "      negative_log_likelihood = tf.reduce_mean(\n",
    "          tf.keras.losses.sparse_categorical_crossentropy(labels, probs))\n",
    "\n",
    "      if dataset_name == 'clean':\n",
    "        metrics[f'{dataset_split}/negative_log_likelihood'].update_state(\n",
    "            negative_log_likelihood)\n",
    "        metrics[f'{dataset_split}/accuracy'].update_state(labels, probs)\n",
    "        metrics[f'{dataset_split}/ece'].add_batch(probs, label=labels)\n",
    "      else:\n",
    "        corrupt_metrics['test/nll_{}'.format(dataset_name)].update_state(\n",
    "            negative_log_likelihood)\n",
    "        corrupt_metrics['test/accuracy_{}'.format(dataset_name)].update_state(\n",
    "            labels, probs)\n",
    "        corrupt_metrics['test/ece_{}'.format(dataset_name)].add_batch(\n",
    "            probs, label=labels)\n",
    "    # for _ in tf.range(tf.cast(num_steps, tf.int32)): #올바른 복제본 별 데이터를 단위에 맞춰서 제공\n",
    "    #   #strategy.run(step_fn, args=(next(iterator),))\n",
    "    #   step_fn(next(iterator))\n",
    "    step_fn(next(iterator))\n",
    "\n",
    "  metrics.update({'test/ms_per_example': tf.keras.metrics.Mean()})\n",
    "  metrics.update({'train/ms_per_example': tf.keras.metrics.Mean()})\n",
    "\n",
    "  train_iterator = iter(train_dataset)\n",
    "  start_time = time.time()\n",
    "  tb_callback = None\n",
    "  if FLAGS.collect_profile:\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "        profile_batch=(100, 102),\n",
    "        log_dir=os.path.join(FLAGS.output_dir, 'logs'))\n",
    "    tb_callback.set_model(model)\n",
    "  for epoch in range(initial_epoch, FLAGS.train_epochs):\n",
    "    logging.info('Starting to run epoch: %s', epoch)\n",
    "    if tb_callback:\n",
    "      tb_callback.on_epoch_begin(epoch)\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    #train_step(train_iterator)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for _ in range(steps_per_epoch):\n",
    "      inputs = next(train_iterator)\n",
    "      images = inputs['features']\n",
    "      labels = inputs['labels']\n",
    "      with tf.GradientTape() as tape:\n",
    "        print('333')\n",
    "        logits = model(images, training=True)\n",
    "        print('444')\n",
    "        if FLAGS.label_smoothing == 0.:\n",
    "          print('555')\n",
    "          negative_log_likelihood = tf.reduce_mean(\n",
    "              tf.keras.losses.sparse_categorical_crossentropy(labels,\n",
    "                                                              logits,\n",
    "                                                              from_logits=True))\n",
    "          print('666')\n",
    "      print('888')\n",
    "      l2_loss = sum(model.losses)\n",
    "      print('999')\n",
    "      loss = negative_log_likelihood + l2_loss\n",
    "      print('101010')\n",
    "      # Scale the loss given the TPUStrategy will reduce sum all gradients.\n",
    "      print('11 11 11 11 11')\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      print('12 12 12 12 12 ')\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "      print('13 13 13 13 13 ')\n",
    "\n",
    "      print('14 14 14 14 14 ')\n",
    "      probs = tf.nn.softmax(logits)\n",
    "      print('15 15 15 15 15 ')\n",
    "      metrics['train/ece'].add_batch(probs, label=labels)\n",
    "      metrics['train/loss'].update_state(loss)\n",
    "      metrics['train/negative_log_likelihood'].update_state(\n",
    "        negative_log_likelihood)\n",
    "      metrics['train/accuracy'].update_state(labels, logits)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #train_step(next(train_iterator))\n",
    "\n",
    "    ms_per_example = (time.time() - train_start_time) * 1e6 / batch_size\n",
    "    metrics['train/ms_per_example'].update_state(ms_per_example)\n",
    "\n",
    "    current_step = (epoch + 1) * steps_per_epoch\n",
    "    max_steps = steps_per_epoch * FLAGS.train_epochs\n",
    "    time_elapsed = time.time() - start_time\n",
    "    steps_per_sec = float(current_step) / time_elapsed\n",
    "    eta_seconds = (max_steps - current_step) / steps_per_sec\n",
    "    message = ('{:.1%} completion: epoch {:d}/{:d}. {:.1f} steps/s. '\n",
    "               'ETA: {:.0f} min. Time elapsed: {:.0f} min'.format(\n",
    "                   current_step / max_steps,\n",
    "                   epoch + 1,\n",
    "                   FLAGS.train_epochs,\n",
    "                   steps_per_sec,\n",
    "                   eta_seconds / 60,\n",
    "                   time_elapsed / 60))\n",
    "    logging.info(message)\n",
    "    if tb_callback:\n",
    "      tb_callback.on_epoch_end(epoch)\n",
    "\n",
    "    if validation_dataset:\n",
    "      validation_iterator = iter(validation_dataset)\n",
    "      test_step(\n",
    "          validation_iterator, 'validation', 'clean', steps_per_validation)\n",
    "    datasets_to_evaluate = {'clean': test_datasets['clean']}\n",
    "    #datasets_to_evaluate = test_datasets\n",
    "    for dataset_name, test_dataset in datasets_to_evaluate.items():\n",
    "      test_iterator = iter(test_dataset)\n",
    "      logging.info('Testing on dataset %s', dataset_name)\n",
    "      logging.info('Starting to run eval at epoch: %s', epoch)\n",
    "      test_start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #test_step(test_iterator, 'test', dataset_name, steps_per_eval)\n",
    "\n",
    "      for _ in range(steps_per_epoch):\n",
    "        inputs = next(test_iterator)\n",
    "        images = inputs['features']\n",
    "        labels = inputs['labels']    \n",
    "        logits = model(images, training=False)\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        negative_log_likelihood = tf.reduce_mean(\n",
    "              tf.keras.losses.sparse_categorical_crossentropy(labels, probs))\n",
    "        \n",
    "        dataset_split = 'test'\n",
    "        metrics[f'{dataset_split}/negative_log_likelihood'].update_state(\n",
    "                negative_log_likelihood)\n",
    "        metrics[f'{dataset_split}/accuracy'].update_state(labels, probs)\n",
    "        metrics[f'{dataset_split}/ece'].add_batch(probs, label=labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #test_step(next(test_iterator), 'test', dataset_name, steps_per_eval)\n",
    "\n",
    "      ms_per_example = (time.time() - test_start_time) * 1e6 / batch_size\n",
    "      metrics['test/ms_per_example'].update_state(ms_per_example)\n",
    "\n",
    "      logging.info('Done with testing on %s', dataset_name)\n",
    "\n",
    "    corrupt_results = {}\n",
    "    if (FLAGS.corruptions_interval > 0 and\n",
    "        (epoch + 1) % FLAGS.corruptions_interval == 0):\n",
    "      corrupt_results = aggregate_corrupt_metrics(corrupt_metrics,\n",
    "                                                        corruption_types)\n",
    "\n",
    "    logging.info('Train Loss: %.4f, Accuracy: %.2f%%',\n",
    "                 metrics['train/loss'].result(),\n",
    "                 metrics['train/accuracy'].result() * 100)\n",
    "    logging.info('Test NLL: %.4f, Accuracy: %.2f%%',\n",
    "                 metrics['test/negative_log_likelihood'].result(),\n",
    "                 metrics['test/accuracy'].result() * 100)\n",
    "    total_results = {name: metric.result() for name, metric in metrics.items()}\n",
    "    total_results.update(corrupt_results)\n",
    "    # Metrics from Robustness Metrics (like ECE) will return a dict with a\n",
    "    # single key/value, instead of a scalar.\n",
    "    total_results = {\n",
    "        k: (list(v.values())[0] if isinstance(v, dict) else v)\n",
    "        for k, v in total_results.items()\n",
    "    }\n",
    "    with summary_writer.as_default():\n",
    "      for name, result in total_results.items():\n",
    "        tf.summary.scalar(name, result, step=epoch + 1)\n",
    "\n",
    "    for metric in metrics.values():\n",
    "      metric.reset_states()\n",
    "\n",
    "    if (FLAGS.checkpoint_interval > 0 and\n",
    "        (epoch + 1) % FLAGS.checkpoint_interval == 0):\n",
    "      checkpoint_name = checkpoint.save(\n",
    "          os.path.join(FLAGS.output_dir, 'checkpoint'))\n",
    "      logging.info('Saved checkpoint to %s', checkpoint_name)\n",
    "\n",
    "  final_checkpoint_name = checkpoint.save(\n",
    "      os.path.join(FLAGS.output_dir, 'checkpoint'))\n",
    "  logging.info('Saved last checkpoint to %s', final_checkpoint_name)\n",
    "  with summary_writer.as_default():\n",
    "    hp.hparams({\n",
    "        'base_learning_rate': FLAGS.base_learning_rate,\n",
    "        'one_minus_momentum': FLAGS.one_minus_momentum,\n",
    "        'l2': FLAGS.l2,\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SaveCheckpoints_cifar_wideresnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0031b670d8e447c1ad8230eb2ce303d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "00b6f21dd98c4010a5edbcf8efa42bad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085273ecdacb4a939b242fa7fa0c8a71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08611fe2c829430280a371a8e674f4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a8216fa497f4fadacac97aa33a2882e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1b618dbf37304f54a76244595c354de7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c69e4bc3a37d4724b77d978eeddaa23c",
       "IPY_MODEL_aa79990886cf444b8b77775b991e26e7"
      ],
      "layout": "IPY_MODEL_3bfd5704f76140dd98515461bc3048e0"
     }
    },
    "2434b90fef484b728ba9c5a8635f8275": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28d3a7201f264748aef2d66b7266b06f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dd2341ae4064b8a8c20b660b4be518f",
       "IPY_MODEL_bf5fdebd801949d8ac62d42335dc0b21"
      ],
      "layout": "IPY_MODEL_7852f0aec1a447b39044d4a945a6b061"
     }
    },
    "3554575f38b641069c956b3dead472f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35d03895fcec4c5caf7a8289299373ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35dd98803513440bb0945480b8841391": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a176013226d444c83f74a67305edbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f905702355748eea3e837373b426ef9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a8216fa497f4fadacac97aa33a2882e",
      "value": 1
     }
    },
    "3bfd5704f76140dd98515461bc3048e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dd2341ae4064b8a8c20b660b4be518f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling cifar10-train.tfrecord...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfff4c3d52284b91963b46e3b704b3e6",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0031b670d8e447c1ad8230eb2ce303d2",
      "value": 50000
     }
    },
    "3f31784765414b89b1fdc5329520d51c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Size...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00b6f21dd98c4010a5edbcf8efa42bad",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fee5c32e94b24a5a824735017a36e4d2",
      "value": 1
     }
    },
    "3f905702355748eea3e837373b426ef9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4594dc94e8d04af9a8cbe9ede5a9af09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating splits...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08611fe2c829430280a371a8e674f4f7",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7bc73eab1a1455eb4ee136cc9b46a85",
      "value": 2
     }
    },
    "4bb40d9c66fe4936a02eb2bc330edac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ccfc511845845acac04cf0acce42d45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4b357eace854aa19215be43cb922442",
       "IPY_MODEL_ef6a35f10f254d37a270cae1f48e1e53"
      ],
      "layout": "IPY_MODEL_e7d002292d904b70bd85dcec30b46a5d"
     }
    },
    "4f5591d79e484d138dcf36fdcc8a9676": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f31784765414b89b1fdc5329520d51c",
       "IPY_MODEL_a8edc03628a64bf29446f21fce1114f0"
      ],
      "layout": "IPY_MODEL_cbacbb95817f439388978a200ebc68c3"
     }
    },
    "579f864dc6804738b4e98e4907f2625d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5823097ee6d64ab59812f07f827db710": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58d2d47de219479db56d0b0ce0f5e688": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71200e204bd7409ab0d16eeeeaa0e23f",
       "IPY_MODEL_a96fa29b26d84bff9203d67315f56d51"
      ],
      "layout": "IPY_MODEL_5823097ee6d64ab59812f07f827db710"
     }
    },
    "5a3694e29d3348bf98ccde5fab5851a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c0565b82d754396925fb74ad45936fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4594dc94e8d04af9a8cbe9ede5a9af09",
       "IPY_MODEL_9f5275d80c0e4c6e9184ef0888c08495"
      ],
      "layout": "IPY_MODEL_e9003f4087154331b3d3827e2b243ee3"
     }
    },
    "61f8b0fbd56643de9561022695ff17e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bbfe2bb9caf4968b51255b63e5910a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71200e204bd7409ab0d16eeeeaa0e23f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Extraction completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_085273ecdacb4a939b242fa7fa0c8a71",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bbfe2bb9caf4968b51255b63e5910a1",
      "value": 1
     }
    },
    "7852f0aec1a447b39044d4a945a6b061": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844016ae0da64336bd5a144a9165737a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ed94bff0dc47dc9078cec2fe8c5ff5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8929537d061c4ac69110c7862927e4dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a3bce89d8a24cec891c97d2de3da92c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a176013226d444c83f74a67305edbab",
       "IPY_MODEL_e1e124875c05440fb2668ddd04514954"
      ],
      "layout": "IPY_MODEL_d82660b384554df2be06fb8eca3891f8"
     }
    },
    "8d1f5838cf43466fbf6056d8ba1292ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9512c2e067b74913b3a1934595bac0d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9f5275d80c0e4c6e9184ef0888c08495": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7aded977c194dcaa58bbdb4332c1c7b",
      "placeholder": "​",
      "style": "IPY_MODEL_9f967a3261494499823c584c5944b3d2",
      "value": " 2/2 [00:35&lt;00:00, 22.37s/ splits]"
     }
    },
    "9f967a3261494499823c584c5944b3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7bc73eab1a1455eb4ee136cc9b46a85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a8edc03628a64bf29446f21fce1114f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35dd98803513440bb0945480b8841391",
      "placeholder": "​",
      "style": "IPY_MODEL_f54a480c69b646d092aa13172f053bd3",
      "value": " 162/162 [00:06&lt;00:00, 26.12 MiB/s]"
     }
    },
    "a96fa29b26d84bff9203d67315f56d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_844016ae0da64336bd5a144a9165737a",
      "placeholder": "​",
      "style": "IPY_MODEL_2434b90fef484b728ba9c5a8635f8275",
      "value": " 1/1 [00:06&lt;00:00,  6.15s/ file]"
     }
    },
    "aa79990886cf444b8b77775b991e26e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af95fa47862a4d28a2e63591a00f6a91",
      "placeholder": "​",
      "style": "IPY_MODEL_61f8b0fbd56643de9561022695ff17e0",
      "value": " 10000/10000 [00:00&lt;00:00, 106344.02 examples/s]"
     }
    },
    "acf93c4686d44b96b54020e73b30168a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af95fa47862a4d28a2e63591a00f6a91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b57c2622081c4402af2c6b1745beddd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc4e74d45ce14cc1af0d6dffdc375141": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3278b6950934cd98656e60ab5337a6a",
       "IPY_MODEL_cdb3d3b635d84a51b5e7381e6033b2e0"
      ],
      "layout": "IPY_MODEL_8d1f5838cf43466fbf6056d8ba1292ef"
     }
    },
    "bf5fdebd801949d8ac62d42335dc0b21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e97b2c453b0b4384a78a2dbfeb8035af",
      "placeholder": "​",
      "style": "IPY_MODEL_4bb40d9c66fe4936a02eb2bc330edac1",
      "value": " 50000/50000 [00:00&lt;00:00, 91667.94 examples/s]"
     }
    },
    "c572993a4a8d48ea91f67a01510ff652": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c69e4bc3a37d4724b77d978eeddaa23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling cifar10-test.tfrecord...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b57c2622081c4402af2c6b1745beddd1",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9512c2e067b74913b3a1934595bac0d7",
      "value": 10000
     }
    },
    "cbacbb95817f439388978a200ebc68c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdb3d3b635d84a51b5e7381e6033b2e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35d03895fcec4c5caf7a8289299373ed",
      "placeholder": "​",
      "style": "IPY_MODEL_f8f8493ce29e4057a205d33a1e6da541",
      "value": " 10000/10000 [00:05&lt;00:00, 1722.48 examples/s]"
     }
    },
    "cfff4c3d52284b91963b46e3b704b3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3278b6950934cd98656e60ab5337a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating test examples...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acf93c4686d44b96b54020e73b30168a",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_579f864dc6804738b4e98e4907f2625d",
      "value": 10000
     }
    },
    "d82660b384554df2be06fb8eca3891f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1e124875c05440fb2668ddd04514954": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ed94bff0dc47dc9078cec2fe8c5ff5",
      "placeholder": "​",
      "style": "IPY_MODEL_5a3694e29d3348bf98ccde5fab5851a7",
      "value": " 1/1 [00:06&lt;00:00,  6.24s/ url]"
     }
    },
    "e4b357eace854aa19215be43cb922442": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating train examples...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8929537d061c4ac69110c7862927e4dd",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c572993a4a8d48ea91f67a01510ff652",
      "value": 50000
     }
    },
    "e7aded977c194dcaa58bbdb4332c1c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d002292d904b70bd85dcec30b46a5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9003f4087154331b3d3827e2b243ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e97b2c453b0b4384a78a2dbfeb8035af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eee8f17f26e342a49f485fd673fb0487": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef6a35f10f254d37a270cae1f48e1e53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eee8f17f26e342a49f485fd673fb0487",
      "placeholder": "​",
      "style": "IPY_MODEL_3554575f38b641069c956b3dead472f2",
      "value": " 50000/50000 [00:28&lt;00:00, 1760.39 examples/s]"
     }
    },
    "f54a480c69b646d092aa13172f053bd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8f8493ce29e4057a205d33a1e6da541": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fee5c32e94b24a5a824735017a36e4d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
