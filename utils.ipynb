{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27936092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Utilities for CIFAR-10 and CIFAR-100.\"\"\"\n",
    "\n",
    "import os\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# common flags\n",
    "flags.DEFINE_float('base_learning_rate', 0.1,\n",
    "                   'Base learning rate when total batch size is 128. It is '\n",
    "                   'scaled by the ratio of the total batch size to 128.')\n",
    "flags.DEFINE_integer('checkpoint_interval', 25,\n",
    "                     'Number of epochs between saving checkpoints. Use -1 to '\n",
    "                     'never save checkpoints.')\n",
    "# TODO(ghassen): consider adding CIFAR-100-C to TFDS.\n",
    "flags.DEFINE_string('cifar100_c_path', None,\n",
    "                    'Path to the TFRecords files for CIFAR-100-C. Only valid '\n",
    "                    '(and required) if dataset is cifar100 and corruptions.')\n",
    "flags.DEFINE_integer('corruptions_interval', -1,\n",
    "                     'Number of epochs between evaluating on the corrupted '\n",
    "                     'test data. Use -1 to never evaluate.')\n",
    "flags.DEFINE_enum('dataset', 'cifar10',\n",
    "                  enum_values=['cifar10', 'cifar100'],\n",
    "                  help='Dataset.')\n",
    "flags.DEFINE_string('data_dir', None,\n",
    "                    'data_dir to be used for tfds dataset construction.'\n",
    "                    'It is required when training with cloud TPUs')\n",
    "flags.DEFINE_bool('download_data', False,\n",
    "                  'Whether to download data locally when initializing a '\n",
    "                  'dataset.')\n",
    "flags.DEFINE_float('l2', 2e-4, 'L2 regularization coefficient.')\n",
    "flags.DEFINE_float('lr_decay_ratio', 0.2, 'Amount to decay learning rate.')\n",
    "flags.DEFINE_list('lr_decay_epochs', ['60', '120', '160'],\n",
    "                  'Epochs to decay learning rate by.')\n",
    "flags.DEFINE_integer('lr_warmup_epochs', 1,\n",
    "                     'Number of epochs for a linear warmup to the initial '\n",
    "                     'learning rate. Use 0 to do no warmup.')\n",
    "flags.DEFINE_integer('num_bins', 15, 'Number of bins for ECE.')\n",
    "flags.DEFINE_float('one_minus_momentum', 0.1, 'Optimizer momentum.')\n",
    "flags.DEFINE_string('output_dir', '/tmp/cifar', 'Output directory.')\n",
    "flags.DEFINE_integer('per_core_batch_size', 64,\n",
    "                     'Batch size per TPU core/GPU. The number of new '\n",
    "                     'datapoints gathered per batch is this number divided by '\n",
    "                     'ensemble_size (we tile the batch by that # of times).')\n",
    "flags.DEFINE_integer('seed', 42, 'Random seed.')\n",
    "flags.DEFINE_integer('train_epochs', 200, 'Number of training epochs.')\n",
    "flags.DEFINE_float('train_proportion', default=1.0,\n",
    "                   help='only use a proportion of training set.')\n",
    "flags.register_validator('train_proportion',\n",
    "                         lambda tp: tp > 0.0 and tp <= 1.0,\n",
    "                         message='--train_proportion must be in (0, 1].')\n",
    "\n",
    "# Accelerator flags.\n",
    "flags.DEFINE_bool('use_gpu', False, 'Whether to run on GPU or otherwise TPU.')\n",
    "flags.DEFINE_integer('num_cores', 8, 'Number of TPU cores or number of GPUs.')\n",
    "flags.DEFINE_string('tpu', None,\n",
    "                    'Name of the TPU. Only used if use_gpu is False.')\n",
    "flags.DEFINE_bool('use_bfloat16', False, 'Whether to use mixed precision.')\n",
    "\n",
    "\n",
    "def load_cifar100_c(corruption_name,\n",
    "                    corruption_intensity,\n",
    "                    batch_size,\n",
    "                    use_bfloat16,\n",
    "                    path,\n",
    "                    drop_remainder=True,\n",
    "                    normalize=True,\n",
    "                    standarize=True):\n",
    "  \"\"\"Loads CIFAR-100-C dataset.\"\"\"\n",
    "  if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  filename = path + '{0}-{1}.tfrecords'.format(corruption_name,\n",
    "                                               corruption_intensity)\n",
    "  def preprocess(serialized_example):\n",
    "    \"\"\"Preprocess a serialized example for CIFAR100-C.\"\"\"\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.cast(tf.reshape(image, [32, 32, 3]), dtype)\n",
    "    image = tf.image.convert_image_dtype(image, dtype)\n",
    "    image = image / 255  # to convert into the [0, 1) range\n",
    "    if normalize:\n",
    "      mean = tf.constant([0.4914, 0.4822, 0.4465], dtype=dtype)\n",
    "      std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype)\n",
    "      image = (image - mean) / std\n",
    "    elif standarize:\n",
    "      # Normalize per-image using mean/stddev computed across pixels.\n",
    "      image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(features['label'], dtype)\n",
    "    return image, label\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset(filename, buffer_size=16 * 1000 * 1000)\n",
    "  dataset = dataset.map(\n",
    "      preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def load_cifar10_c(corruption_name,\n",
    "                   corruption_intensity,\n",
    "                   batch_size,\n",
    "                   use_bfloat16,\n",
    "                   drop_remainder=True,\n",
    "                   normalize=True):\n",
    "  \"\"\"Loads CIFAR-10-C dataset.\"\"\"\n",
    "  if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  corruption = corruption_name + '_' + str(corruption_intensity)\n",
    "  def preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype)\n",
    "    if normalize:\n",
    "      # We use the convention of mean = np.mean(train_images, axis=(0,1,2))\n",
    "      # and std = np.std(train_images, axis=(0,1,2)).\n",
    "      mean = tf.constant([0.4914, 0.4822, 0.4465], dtype=dtype)\n",
    "      std = tf.constant([0.2470, 0.2435, 0.2616], dtype=dtype)\n",
    "      # Previously, std = np.mean(np.std(train_images, axis=(1, 2)), axis=0)\n",
    "      # which gave std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype).\n",
    "      # However, we change convention to use the std over the entire training\n",
    "      # set instead.\n",
    "      image = (image - mean) / std\n",
    "    label = tf.cast(label, dtype)\n",
    "    return image, label\n",
    "\n",
    "  dataset = tfds.load(name='cifar10_corrupted/{}'.format(corruption),\n",
    "                      split=tfds.Split.TEST,\n",
    "                      as_supervised=True)\n",
    "  dataset = dataset.map(\n",
    "      preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# TODO(ghassen,trandustin): Push this metadata upstream to TFDS.\n",
    "def load_corrupted_test_info(dataset):\n",
    "  \"\"\"Loads information for CIFAR-10-C.\"\"\"\n",
    "  if dataset == 'cifar10':\n",
    "    corruption_types = [\n",
    "        'gaussian_noise',\n",
    "        'shot_noise',\n",
    "        'impulse_noise',\n",
    "        'defocus_blur',\n",
    "        'frosted_glass_blur',\n",
    "        'motion_blur',\n",
    "        'zoom_blur',\n",
    "        'snow',\n",
    "        'frost',\n",
    "        'fog',\n",
    "        'brightness',\n",
    "        'contrast',\n",
    "        'elastic',\n",
    "        'pixelate',\n",
    "        'jpeg_compression',\n",
    "    ]\n",
    "  else:\n",
    "    corruption_types = [\n",
    "        'brightness',\n",
    "        'contrast',\n",
    "        'defocus_blur',\n",
    "        'elastic_transform',\n",
    "        'fog',\n",
    "        'frost',\n",
    "        'glass_blur',  # Called frosted_glass_blur in CIFAR-10.\n",
    "        'gaussian_blur',\n",
    "        'gaussian_noise',\n",
    "        'impulse_noise',\n",
    "        'jpeg_compression',\n",
    "        'pixelate',\n",
    "        'saturate',\n",
    "        'shot_noise',\n",
    "        'spatter',\n",
    "        'speckle_noise',  # Does not exist for CIFAR-10.\n",
    "        'zoom_blur',\n",
    "    ]\n",
    "  max_intensity = 5\n",
    "  return corruption_types, max_intensity\n",
    "\n",
    "\n",
    "# TODO(baselines): Remove reliance on hard-coded metric names.\n",
    "def aggregate_corrupt_metrics(metrics,\n",
    "                              corruption_types,\n",
    "                              max_intensity=5,\n",
    "                              log_fine_metrics=False,\n",
    "                              corrupt_diversity=None,\n",
    "                              output_dir=None,\n",
    "                              prefix='test'):\n",
    "  \"\"\"Aggregates metrics across intensities and corruption types.\n",
    "  Args:\n",
    "    metrics: Dictionary of tf.keras.metrics to be aggregated.\n",
    "    corruption_types: List of corruption types.\n",
    "    max_intensity: Int, of maximum intensity.\n",
    "    log_fine_metrics: Bool, whether log fine metrics to main training script.\n",
    "    corrupt_diversity: Dictionary of diversity metrics on corrupted datasets.\n",
    "    output_dir: Str, the path to save the aggregated results.\n",
    "    prefix: Str, the prefix before metrics such as 'test', 'lineareval'.\n",
    "  Returns:\n",
    "    Dictionary of aggregated results.\n",
    "  \"\"\"\n",
    "  diversity_keys = ['disagreement', 'cosine_similarity', 'average_kl']\n",
    "  results = {\n",
    "      '{}/nll_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/kl_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/elbo_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/accuracy_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/ece_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/member_acc_mean_corrupted'.format(prefix): 0.,\n",
    "      '{}/member_ece_mean_corrupted'.format(prefix): 0.\n",
    "  }\n",
    "  fine_metrics_results = {}\n",
    "  if corrupt_diversity is not None:\n",
    "    for key in diversity_keys:\n",
    "      results['corrupt_diversity/{}_mean_corrupted'.format(key)] = 0.\n",
    "\n",
    "  for intensity in range(1, max_intensity + 1):\n",
    "    nll = np.zeros(len(corruption_types))\n",
    "    kl = np.zeros(len(corruption_types))\n",
    "    elbo = np.zeros(len(corruption_types))\n",
    "    acc = np.zeros(len(corruption_types))\n",
    "    ece = np.zeros(len(corruption_types))\n",
    "    member_acc = np.zeros(len(corruption_types))\n",
    "    member_ece = np.zeros(len(corruption_types))\n",
    "    disagreement = np.zeros(len(corruption_types))\n",
    "    cosine_similarity = np.zeros(len(corruption_types))\n",
    "    average_kl = np.zeros(len(corruption_types))\n",
    "\n",
    "    for i in range(len(corruption_types)):\n",
    "      dataset_name = '{0}_{1}'.format(corruption_types[i], intensity)\n",
    "      nll[i] = metrics['{0}/nll_{1}'.format(prefix, dataset_name)].result()\n",
    "      if '{0}/kl_{1}'.format(prefix, dataset_name) in metrics.keys():\n",
    "        kl[i] = metrics['{0}/kl_{1}'.format(prefix, dataset_name)].result()\n",
    "      else:\n",
    "        kl[i] = 0.\n",
    "      if '{0}/elbo_{1}'.format(prefix, dataset_name) in metrics.keys():\n",
    "        elbo[i] = metrics['{0}/elbo_{1}'.format(prefix, dataset_name)].result()\n",
    "      else:\n",
    "        elbo[i] = 0.\n",
    "      acc[i] = metrics['{0}/accuracy_{1}'.format(prefix, dataset_name)].result()\n",
    "      ece[i] = metrics['{0}/ece_{1}'.format(prefix, dataset_name)].result()\n",
    "      if '{0}/member_acc_mean_{1}'.format(prefix,\n",
    "                                          dataset_name) in metrics.keys():\n",
    "        member_acc[i] = metrics['{0}/member_acc_mean_{1}'.format(\n",
    "            prefix, dataset_name)].result()\n",
    "      else:\n",
    "        member_acc[i] = 0.\n",
    "      if '{0}/member_ece_mean_{1}'.format(prefix,\n",
    "                                          dataset_name) in metrics.keys():\n",
    "        member_ece[i] = metrics['{0}/member_ece_mean_{1}'.format(\n",
    "            prefix, dataset_name)].result()\n",
    "        member_ece[i] = 0.\n",
    "      if corrupt_diversity is not None:\n",
    "        disagreement[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/disagreement_{}'.format(\n",
    "                dataset_name)].result())\n",
    "        # Normalize the corrupt disagreement by its error rate.\n",
    "        error = 1 - acc[i] + tf.keras.backend.epsilon()\n",
    "        cosine_similarity[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/cosine_similarity_{}'.format(\n",
    "                dataset_name)].result()) / error\n",
    "        average_kl[i] = (\n",
    "            corrupt_diversity['corrupt_diversity/average_kl_{}'.format(\n",
    "                dataset_name)].result())\n",
    "      if log_fine_metrics or output_dir is not None:\n",
    "        fine_metrics_results['{0}/nll_{1}'.format(prefix,\n",
    "                                                  dataset_name)] = nll[i]\n",
    "        fine_metrics_results['{0}/kl_{1}'.format(prefix,\n",
    "                                                 dataset_name)] = kl[i]\n",
    "        fine_metrics_results['{0}/elbo_{1}'.format(prefix,\n",
    "                                                   dataset_name)] = elbo[i]\n",
    "        fine_metrics_results['{0}/accuracy_{1}'.format(prefix,\n",
    "                                                       dataset_name)] = acc[i]\n",
    "        fine_metrics_results['{0}/ece_{1}'.format(prefix,\n",
    "                                                  dataset_name)] = ece[i]\n",
    "        if corrupt_diversity is not None:\n",
    "          fine_metrics_results['corrupt_diversity/disagreement_{}'.format(\n",
    "              dataset_name)] = disagreement[i]\n",
    "          fine_metrics_results['corrupt_diversity/cosine_similarity_{}'.format(\n",
    "              dataset_name)] = cosine_similarity[i]\n",
    "          fine_metrics_results['corrupt_diversity/average_kl_{}'.format(\n",
    "              dataset_name)] = average_kl[i]\n",
    "    avg_nll = np.mean(nll)\n",
    "    avg_kl = np.mean(kl)\n",
    "    avg_elbo = np.mean(elbo)\n",
    "    avg_accuracy = np.mean(acc)\n",
    "    avg_ece = np.mean(ece)\n",
    "    avg_member_acc = np.mean(member_acc)\n",
    "    avg_member_ece = np.mean(member_ece)\n",
    "    results['{0}/nll_mean_{1}'.format(prefix, intensity)] = avg_nll\n",
    "    results['{0}/kl_mean_{1}'.format(prefix, intensity)] = avg_kl\n",
    "    results['{0}/elbo_mean_{1}'.format(prefix, intensity)] = avg_elbo\n",
    "    results['{0}/accuracy_mean_{1}'.format(prefix, intensity)] = avg_accuracy\n",
    "    results['{0}/ece_mean_{1}'.format(prefix, intensity)] = avg_ece\n",
    "    results['{0}/nll_median_{1}'.format(prefix, intensity)] = np.median(nll)\n",
    "    results['{0}/kl_median_{1}'.format(prefix, intensity)] = np.median(kl)\n",
    "    results['{0}/elbo_median_{1}'.format(prefix, intensity)] = np.median(elbo)\n",
    "    results['{0}/accuracy_median_{1}'.format(prefix,\n",
    "                                             intensity)] = np.median(acc)\n",
    "    results['{0}/ece_median_{1}'.format(prefix, intensity)] = np.median(ece)\n",
    "    results['{0}/member_acc_mean_{1}'.format(prefix,\n",
    "                                             intensity)] = avg_member_acc\n",
    "    results['{0}/member_ece_mean_{1}'.format(prefix,\n",
    "                                             intensity)] = avg_member_ece\n",
    "    results['{}/nll_mean_corrupted'.format(prefix)] += avg_nll\n",
    "    results['{}/kl_mean_corrupted'.format(prefix)] += avg_kl\n",
    "    results['{}/elbo_mean_corrupted'.format(prefix)] += avg_elbo\n",
    "    results['{}/accuracy_mean_corrupted'.format(prefix)] += avg_accuracy\n",
    "    results['{}/ece_mean_corrupted'.format(prefix)] += avg_ece\n",
    "    results['{}/member_acc_mean_corrupted'.format(prefix)] += avg_member_acc\n",
    "    results['{}/member_ece_mean_corrupted'.format(prefix)] += avg_member_ece\n",
    "    if corrupt_diversity is not None:\n",
    "      avg_diversity_metrics = [np.mean(disagreement), np.mean(\n",
    "          cosine_similarity), np.mean(average_kl)]\n",
    "      for key, avg in zip(diversity_keys, avg_diversity_metrics):\n",
    "        results['corrupt_diversity/{}_mean_{}'.format(\n",
    "            key, intensity)] = avg\n",
    "        results['corrupt_diversity/{}_mean_corrupted'.format(key)] += avg\n",
    "\n",
    "  results['{}/nll_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/kl_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/elbo_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/accuracy_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/ece_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/member_acc_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  results['{}/member_ece_mean_corrupted'.format(prefix)] /= max_intensity\n",
    "  if corrupt_diversity is not None:\n",
    "    for key in diversity_keys:\n",
    "      results['corrupt_diversity/{}_mean_corrupted'.format(\n",
    "          key)] /= max_intensity\n",
    "\n",
    "  fine_metrics_results.update(results)\n",
    "  if output_dir is not None:\n",
    "    save_file_name = os.path.join(output_dir, 'corrupt_metrics.npz')\n",
    "    with tf.io.gfile.GFile(save_file_name, 'w') as f:\n",
    "      np.save(f, fine_metrics_results)\n",
    "\n",
    "  if log_fine_metrics:\n",
    "    return fine_metrics_results\n",
    "  else:\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
