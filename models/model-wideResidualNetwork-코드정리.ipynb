{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e851fa7",
   "metadata": {},
   "source": [
    "# Wide Residual Network\n",
    "\n",
    "* Wide Residual Network 모델\n",
    "* 출처: https://github.com/google/uncertainty-baselines/blob/9c29b04dc4500a028ec5b9378af9881fed5f8366/uncertainty_baselines/models/wide_resnet.py#L145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a22f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Uncertainty Baselines Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\"\"\"Wide Residual Network.\"\"\"\n",
    "\n",
    "import functools\n",
    "from typing import Any, Dict, Iterable, Optional\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "HP_KEYS = ('bn_l2', 'input_conv_l2', 'group_1_conv_l2', 'group_2_conv_l2',\n",
    "           'group_3_conv_l2', 'dense_kernel_l2', 'dense_bias_l2')\n",
    "\n",
    "BatchNormalization = functools.partial(  # pylint: disable=invalid-name\n",
    "    tf.keras.layers.BatchNormalization,\n",
    "    epsilon=1e-5,  # using epsilon and momentum defaults from Torch\n",
    "    momentum=0.9)\n",
    "\n",
    "\n",
    "def Conv2D(filters, seed=None, **kwargs):  # pylint: disable=invalid-name\n",
    "  \"\"\"Conv2D layer that is deterministically initialized.\"\"\"\n",
    "  default_kwargs = {\n",
    "      'kernel_size': 3,\n",
    "      'padding': 'same',\n",
    "      'use_bias': False,\n",
    "      # Note that we need to use the class constructor for the initializer to\n",
    "      # get deterministic initialization.\n",
    "      'kernel_initializer': tf.keras.initializers.HeNormal(seed=seed),\n",
    "  }\n",
    "  # Override defaults with the passed kwargs.\n",
    "  default_kwargs.update(kwargs)\n",
    "  return tf.keras.layers.Conv2D(filters, **default_kwargs)\n",
    "\n",
    "\n",
    "def basic_block(\n",
    "    inputs: tf.Tensor,\n",
    "    filters: int,\n",
    "    strides: int,\n",
    "    conv_l2: float,\n",
    "    bn_l2: float,\n",
    "    seed: int,\n",
    "    version: int) -> tf.Tensor:\n",
    "  \"\"\"Basic residual block of two 3x3 convs.\n",
    "  Args:\n",
    "    inputs: tf.Tensor.\n",
    "    filters: Number of filters for Conv2D.\n",
    "    strides: Stride dimensions for Conv2D.\n",
    "    conv_l2: L2 regularization coefficient for the conv kernels.\n",
    "    bn_l2: L2 regularization coefficient for the batch norm layers.\n",
    "    seed: random seed used for initialization.\n",
    "    version: 1, indicating the original ordering from He et al. (2015); or 2,\n",
    "      indicating the preactivation ordering from He et al. (2016).\n",
    "  Returns:\n",
    "    tf.Tensor.\n",
    "  \"\"\"\n",
    "  x = inputs\n",
    "  y = inputs\n",
    "  if version == 2:\n",
    "    y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                           gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "    y = tf.keras.layers.Activation('relu')(y)\n",
    "  seeds = tf.random.experimental.stateless_split([seed, seed + 1], 3)[:, 0]\n",
    "  y = Conv2D(filters,\n",
    "             strides=strides,\n",
    "             seed=seeds[0],\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(y)\n",
    "  y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                         gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "  y = tf.keras.layers.Activation('relu')(y)\n",
    "  y = Conv2D(filters,\n",
    "             strides=1,\n",
    "             seed=seeds[1],\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(y)\n",
    "  if version == 1:\n",
    "    y = BatchNormalization(beta_regularizer=tf.keras.regularizers.l2(bn_l2),\n",
    "                           gamma_regularizer=tf.keras.regularizers.l2(bn_l2))(y)\n",
    "  if not x.shape.is_compatible_with(y.shape):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size=1,\n",
    "               strides=strides,\n",
    "               seed=seeds[2],\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(conv_l2))(x)\n",
    "  x = tf.keras.layers.add([x, y])\n",
    "  if version == 1:\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "def group(inputs, filters, strides, num_blocks, conv_l2, bn_l2, version, seed):\n",
    "  \"\"\"Group of residual blocks.\"\"\"\n",
    "  seeds = tf.random.experimental.stateless_split(\n",
    "      [seed, seed + 1], num_blocks)[:, 0]\n",
    "  x = basic_block(\n",
    "      inputs,\n",
    "      filters=filters,\n",
    "      strides=strides,\n",
    "      conv_l2=conv_l2,\n",
    "      bn_l2=bn_l2,\n",
    "      version=version,\n",
    "      seed=seeds[0])\n",
    "  for i in range(num_blocks - 1):\n",
    "    x = basic_block(\n",
    "        x,\n",
    "        filters=filters,\n",
    "        strides=1,\n",
    "        conv_l2=conv_l2,\n",
    "        bn_l2=bn_l2,\n",
    "        version=version,\n",
    "        seed=seeds[i + 1])\n",
    "  return x\n",
    "\n",
    "\n",
    "def _parse_hyperparameters(l2: float, hps: Dict[str, float]):\n",
    "  \"\"\"Extract the L2 parameters for the dense, conv and batch-norm layers.\"\"\"\n",
    "\n",
    "  assert_msg = ('Ambiguous hyperparameter specifications: either l2 or hps '\n",
    "                'must be provided (received {} and {}).'.format(l2, hps))\n",
    "  is_specified = lambda h: bool(h) and all(v is not None for v in h.values())\n",
    "  only_l2_is_specified = l2 is not None and not is_specified(hps)\n",
    "  only_hps_is_specified = l2 is None and is_specified(hps)\n",
    "  assert only_l2_is_specified or only_hps_is_specified, assert_msg\n",
    "  if only_hps_is_specified:\n",
    "    assert_msg = 'hps must contain the keys {}!={}.'.format(HP_KEYS, hps.keys())\n",
    "    assert set(hps.keys()).issuperset(HP_KEYS), assert_msg\n",
    "    return hps\n",
    "  else:\n",
    "    return {k: l2 for k in HP_KEYS}\n",
    "\n",
    "\n",
    "def wide_resnet(\n",
    "    input_shape: Iterable[int],\n",
    "    depth: int,\n",
    "    width_multiplier: int,\n",
    "    num_classes: int,\n",
    "    l2: float,\n",
    "    version: int = 2,\n",
    "    seed: int = 42,\n",
    "    hps: Optional[Dict[str, float]] = None) -> tf.keras.models.Model:\n",
    "  \"\"\"Builds Wide ResNet.\n",
    "  Following Zagoruyko and Komodakis (2016), it accepts a width multiplier on the\n",
    "  number of filters. Using three groups of residual blocks, the network maps\n",
    "  spatial features of size 32x32 -> 16x16 -> 8x8.\n",
    "  Args:\n",
    "    input_shape: tf.Tensor.\n",
    "    depth: Total number of convolutional layers. \"n\" in WRN-n-k. It differs from\n",
    "      He et al. (2015)'s notation which uses the maximum depth of the network\n",
    "      counting non-conv layers like dense.\n",
    "    width_multiplier: Integer to multiply the number of typical filters by. \"k\"\n",
    "      in WRN-n-k.\n",
    "    num_classes: Number of output classes.\n",
    "    l2: L2 regularization coefficient.\n",
    "    version: 1, indicating the original ordering from He et al. (2015); or 2,\n",
    "      indicating the preactivation ordering from He et al. (2016).\n",
    "    seed: random seed used for initialization.\n",
    "    hps: Fine-grained specs of the hyperparameters, as a Dict[str, float].\n",
    "  Returns:\n",
    "    tf.keras.Model.\n",
    "  \"\"\"\n",
    "  l2_reg = tf.keras.regularizers.l2\n",
    "  hps = _parse_hyperparameters(l2, hps)\n",
    "\n",
    "  seeds = tf.random.experimental.stateless_split([seed, seed + 1], 5)[:, 0]\n",
    "  if (depth - 4) % 6 != 0:\n",
    "    raise ValueError('depth should be 6n+4 (e.g., 16, 22, 28, 40).')\n",
    "  num_blocks = (depth - 4) // 6\n",
    "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "  x = Conv2D(16,\n",
    "             strides=1,\n",
    "             seed=seeds[0],\n",
    "             kernel_regularizer=l2_reg(hps['input_conv_l2']))(inputs)\n",
    "  if version == 1:\n",
    "    x = BatchNormalization(beta_regularizer=l2_reg(hps['bn_l2']),\n",
    "                           gamma_regularizer=l2_reg(hps['bn_l2']))(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = group(x,\n",
    "            filters=16 * width_multiplier,\n",
    "            strides=1,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_1_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[1])\n",
    "  x = group(x,\n",
    "            filters=32 * width_multiplier,\n",
    "            strides=2,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_2_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[2])\n",
    "  x = group(x,\n",
    "            filters=64 * width_multiplier,\n",
    "            strides=2,\n",
    "            num_blocks=num_blocks,\n",
    "            conv_l2=hps['group_3_conv_l2'],\n",
    "            bn_l2=hps['bn_l2'],\n",
    "            version=version,\n",
    "            seed=seeds[3])\n",
    "  if version == 2:\n",
    "    x = BatchNormalization(beta_regularizer=l2_reg(hps['bn_l2']),\n",
    "                           gamma_regularizer=l2_reg(hps['bn_l2']))(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "  x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=tf.keras.initializers.HeNormal(seed=seeds[4]),\n",
    "      kernel_regularizer=l2_reg(hps['dense_kernel_l2']),\n",
    "      bias_regularizer=l2_reg(hps['dense_bias_l2']))(x)\n",
    "  return tf.keras.Model(\n",
    "      inputs=inputs,\n",
    "      outputs=x,\n",
    "      name='wide_resnet-{}-{}'.format(depth, width_multiplier))\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    batch_size: Optional[int],\n",
    "    depth: int,\n",
    "    width_multiplier: int,\n",
    "    input_shape: Iterable[int] = (32, 32, 3),\n",
    "    num_classes: int = 10,\n",
    "    l2_weight: float = 0.0,\n",
    "    version: int = 2,\n",
    "    **unused_kwargs: Dict[str, Any]) -> tf.keras.models.Model:\n",
    "  \"\"\"Creates model.\"\"\"\n",
    "  del batch_size  # unused arg\n",
    "  return wide_resnet(input_shape=input_shape,\n",
    "                     depth=depth,\n",
    "                     width_multiplier=width_multiplier,\n",
    "                     num_classes=num_classes,\n",
    "                     l2=l2_weight,\n",
    "                     version=version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
